{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7669478,
          "sourceType": "datasetVersion",
          "datasetId": 4473093
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3764d9a3996a45b6852090c3db2641fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6dc7a5a1cc24beeb558a4888592e3ad"
            ],
            "layout": "IPY_MODEL_c72f1964cf254fbf9af8239f7cc3f101"
          }
        },
        "05e98334d1234ae097796d9f6d432df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbaadff9b5a048068ea36e32d36ec072",
            "placeholder": "​",
            "style": "IPY_MODEL_f287634448fc464e9d56eba8b8cde3d7",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "6ab2f7e15bd64842b4a785d3b52e791e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9f3de8ed886e49d483cc5a501ef22c28",
            "placeholder": "​",
            "style": "IPY_MODEL_9a5ccabf2a694449bd9b679303147bb2",
            "value": "mahmoud66"
          }
        },
        "c6183c60b00b4454b04a8ec2cd36b8af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4215ab8bdd614eee85ae59a3bef8d6e5",
            "placeholder": "​",
            "style": "IPY_MODEL_e7ed47ce6d294d08af1f6cb46275400c",
            "value": ""
          }
        },
        "7a6485e677be4e0386cc267784eba483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3738be5413554b58b1549d0b83544b97",
            "style": "IPY_MODEL_95e22770fceb4567a3744c9a4f6a7fe8",
            "tooltip": ""
          }
        },
        "fcaaf5d9a85744989e4c91ef8a3dc205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68775272f8dc4360a6ab018fa9ab37b3",
            "placeholder": "​",
            "style": "IPY_MODEL_6bb4f6a2627c44158bf2005236228842",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "c72f1964cf254fbf9af8239f7cc3f101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "fbaadff9b5a048068ea36e32d36ec072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f287634448fc464e9d56eba8b8cde3d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f3de8ed886e49d483cc5a501ef22c28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a5ccabf2a694449bd9b679303147bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4215ab8bdd614eee85ae59a3bef8d6e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7ed47ce6d294d08af1f6cb46275400c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3738be5413554b58b1549d0b83544b97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e22770fceb4567a3744c9a4f6a7fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "68775272f8dc4360a6ab018fa9ab37b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bb4f6a2627c44158bf2005236228842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d62ea2a05f6c4f3783f75f27a89fb5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc95570f12fb41109f75582795780984",
            "placeholder": "​",
            "style": "IPY_MODEL_c9e9282e97814fde8b8d53a2baa7801f",
            "value": "Connecting..."
          }
        },
        "cc95570f12fb41109f75582795780984": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9e9282e97814fde8b8d53a2baa7801f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6dc7a5a1cc24beeb558a4888592e3ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3e5b80cc2384b708df8f9f04d7a88a9",
            "placeholder": "​",
            "style": "IPY_MODEL_2804333deafd45a6925d0b48d7202a4b",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "d3e5b80cc2384b708df8f9f04d7a88a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2804333deafd45a6925d0b48d7202a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Installs"
      ],
      "metadata": {
        "id": "VpYvjhbX_VNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggelhub\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T13:09:06.789273Z",
          "iopub.execute_input": "2025-04-04T13:09:06.789592Z",
          "iopub.status.idle": "2025-04-04T13:09:12.785913Z",
          "shell.execute_reply.started": "2025-04-04T13:09:06.789563Z",
          "shell.execute_reply": "2025-04-04T13:09:12.785085Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80x57kuH_VNc",
        "outputId": "f5583c45-499f-4756-f5ae-001d838e9a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement kaggelhub (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for kaggelhub\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "kagglehub.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "3764d9a3996a45b6852090c3db2641fa",
            "05e98334d1234ae097796d9f6d432df3",
            "6ab2f7e15bd64842b4a785d3b52e791e",
            "c6183c60b00b4454b04a8ec2cd36b8af",
            "7a6485e677be4e0386cc267784eba483",
            "fcaaf5d9a85744989e4c91ef8a3dc205",
            "c72f1964cf254fbf9af8239f7cc3f101",
            "fbaadff9b5a048068ea36e32d36ec072",
            "f287634448fc464e9d56eba8b8cde3d7",
            "9f3de8ed886e49d483cc5a501ef22c28",
            "9a5ccabf2a694449bd9b679303147bb2",
            "4215ab8bdd614eee85ae59a3bef8d6e5",
            "e7ed47ce6d294d08af1f6cb46275400c",
            "3738be5413554b58b1549d0b83544b97",
            "95e22770fceb4567a3744c9a4f6a7fe8",
            "68775272f8dc4360a6ab018fa9ab37b3",
            "6bb4f6a2627c44158bf2005236228842",
            "d62ea2a05f6c4f3783f75f27a89fb5fd",
            "cc95570f12fb41109f75582795780984",
            "c9e9282e97814fde8b8d53a2baa7801f",
            "b6dc7a5a1cc24beeb558a4888592e3ad",
            "d3e5b80cc2384b708df8f9f04d7a88a9",
            "2804333deafd45a6925d0b48d7202a4b"
          ]
        },
        "id": "qdOYTL_h_zV6",
        "outputId": "66e14cf9-9483-4004-8af6-c41887439f5c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3764d9a3996a45b6852090c3db2641fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle credentials set.\n",
            "Kaggle credentials successfully validated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_df_train = kagglehub.dataset_download(\n",
        "  \"mohamedlotfy50/wmt-2014-english-german\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO_Bmjz6_9PD",
        "outputId": "c55e5b6f-e10f-4d82-a467-2588a1782edc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mohamedlotfy50/wmt-2014-english-german?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 555M/555M [00:14<00:00, 39.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/kaggle/\n",
        "!mkdir /content/kaggle/input"
      ],
      "metadata": {
        "id": "eomyCabXAJuK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /root/.cache/kagglehub/datasets/mohamedlotfy50/wmt-2014-english-german/versions/1/* /content/kaggle/input/"
      ],
      "metadata": {
        "id": "FSURRldn_Ya6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "ex5NtJA5_VNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import sentencepiece as spm\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import sys\n",
        "import os\n",
        "import yaml\n",
        "from transformers import AutoTokenizer\n",
        "from torch.optim import Adam\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import random"
      ],
      "metadata": {
        "trusted": true,
        "id": "QJKdnWPi_VNd"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "5IqqjdoI_VNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WMT14Dataset(Dataset):\n",
        "    def __init__(self, csv_file, max_length=512, src_lang=\"de\", tgt_lang=\"en\", tokenizer=None, data_percentage=0.1):\n",
        "        self.data = pd.read_csv(csv_file, lineterminator=\"\\n\")\n",
        "        src_texts = self.data[src_lang].tolist()\n",
        "        tgt_texts = self.data[tgt_lang].tolist()\n",
        "        n_rows = len(src_texts)\n",
        "        rand_start = random.randint(0, n_rows - int(data_percentage*n_rows))\n",
        "        self.src_texts = src_texts[rand_start : rand_start + int(data_percentage*n_rows)]\n",
        "        self.tgt_texts = tgt_texts[rand_start : rand_start + int(data_percentage*n_rows)]\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.src_texts[idx]\n",
        "        y = self.tgt_texts[idx]\n",
        "        if self.tokenizer is not None:\n",
        "            encoding_x = self.tokenizer(\n",
        "                x,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "                max_length=self.max_length,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            encoding_y = self.tokenizer(\n",
        "                y,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "                max_length=self.max_length,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "        return {\n",
        "            \"input_ids\": encoding_x[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding_x[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": encoding_y[\"input_ids\"].squeeze(0)\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "LE7zFp2s_VNf"
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "Jta8W2PU_VNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.n_heads = n_heads\n",
        "        self.d_model = d_model\n",
        "        self.attention = ScaledDotProductAttention()\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "        self.W = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n",
        "        q, k, v = self.split(q), self.split(k), self.split(v)\n",
        "\n",
        "        v, scores = self.attention(q, k, v)\n",
        "\n",
        "        out = self.concat(v)\n",
        "        out = self.W(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def split(self, tensor):\n",
        "        B, seq_len, d_model = tensor.shape\n",
        "        return tensor.view(B, seq_len, self.n_heads, d_model//self.n_heads).transpose(1, 2)\n",
        "\n",
        "    def concat(self, tensor):\n",
        "        B, n_heads, seq_len, d_tensor = tensor.shape\n",
        "        d_model = n_heads * d_tensor\n",
        "\n",
        "        tensor = tensor.transpose(1, 2)\n",
        "        tensor = tensor.contiguous().view(B, seq_len, d_model)\n",
        "        return tensor\n",
        "\n",
        "\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None, e=1e-12):\n",
        "        k_t = k.transpose(2, 3)\n",
        "        B, heads, seq_len, d_tensor = q.shape\n",
        "\n",
        "        scores = (q @ k_t)/math.sqrt(d_tensor)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask==0, -100000)\n",
        "\n",
        "        scores = self.softmax(scores)\n",
        "        v = scores @ v\n",
        "        return v, scores\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
        "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
        "        self.eps = 1e-12\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "\n",
        "        out = (x - mean) / torch.sqrt(var)\n",
        "        out = self.gamma * out + self.beta\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedForwardLayer(nn.Module):\n",
        "    def __init__(self, d_model, hidden=32):\n",
        "        super(FeedForwardLayer, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, hidden)\n",
        "        self.linear2 = nn.Linear(hidden, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, ff_hidden, n_heads):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.ff = FeedForwardLayer(d_model=d_model, hidden=ff_hidden)\n",
        "        self.mh_attn = MultiHeadAttention(d_model=d_model, n_heads=n_heads)\n",
        "        self.layer_norm = LayerNorm(d_model=d_model)\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        _x = x\n",
        "        #Attention\n",
        "        x = self.mh_attn(q=x, k=x, v=x, mask=src_mask)\n",
        "        #LayerNorm\n",
        "        x = self.layer_norm(x + _x)\n",
        "        _x = x\n",
        "        #FF\n",
        "        x = self.ff(x)\n",
        "        x = self.layer_norm(x + _x)\n",
        "        return x\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    compute sinusoid encoding.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, max_len, device):\n",
        "        \"\"\"\n",
        "        constructor of sinusoid encoding class\n",
        "\n",
        "        :param d_model: dimension of model\n",
        "        :param max_len: max sequence length\n",
        "        :param device: hardware device setting\n",
        "        \"\"\"\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        # same size with input matrix (for adding with input matrix)\n",
        "        self.encoding = torch.zeros(max_len, d_model, device=device)\n",
        "        self.encoding.requires_grad = False  # we don't need to compute gradient\n",
        "\n",
        "        pos = torch.arange(0, max_len, device=device)\n",
        "        pos = pos.float().unsqueeze(dim=1)\n",
        "        # 1D => 2D unsqueeze to represent word's position\n",
        "\n",
        "        _2i = torch.arange(0, d_model, step=2, device=device).float()\n",
        "        # 'i' means index of d_model (e.g. embedding size = 50, 'i' = [0,50])\n",
        "        # \"step=2\" means 'i' multiplied with two (same with 2 * i)\n",
        "\n",
        "        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n",
        "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n",
        "        # compute positional encoding to consider positional information of words\n",
        "\n",
        "    def forward(self, x):\n",
        "        # self.encoding\n",
        "        # [max_len = 512, d_model = 512]\n",
        "\n",
        "        batch_size, seq_len = x.size()\n",
        "        # [batch_size = 128, seq_len = 30]\n",
        "\n",
        "        return self.encoding[:seq_len, :]\n",
        "        # [seq_len = 30, d_model = 512]\n",
        "        # it will add with tok_emb : [128, 30, 512]\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, enc_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, device):\n",
        "        super().__init__()\n",
        "        self.emb = TransformerEmbedding(enc_voc_size, d_model, max_len, device)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(d_model=d_model,\n",
        "                                                  ff_hidden=ffn_hidden,\n",
        "                                                  n_heads=n_head) for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        x = self.emb(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask)\n",
        "        return x\n",
        "\n",
        "class TokenEmbedding(nn.Embedding):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super(TokenEmbedding, self).__init__(num_embeddings=vocab_size, embedding_dim=d_model, padding_idx=0)\n",
        "\n",
        "\n",
        "\n",
        "class TransformerEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, max_len, device):\n",
        "        super(TransformerEmbedding, self).__init__()\n",
        "        self.tok_emb = TokenEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
        "        self.pos_emb = PositionalEncoding(d_model, max_len, device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        tok_emb = self.tok_emb(x)\n",
        "        return tok_emb\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, n_heads, d_model, hidden):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.n_heads = n_heads\n",
        "        self.d_model = d_model\n",
        "        self.mh_attn = MultiHeadAttention(d_model=d_model, n_heads=n_heads)\n",
        "        self.enc_dec_attn = MultiHeadAttention(d_model=d_model, n_heads=n_heads)\n",
        "        self.ffn = FeedForwardLayer(d_model=d_model, hidden=hidden)\n",
        "        self.layer_norm1 = LayerNorm(d_model=d_model)\n",
        "        self.layer_norm2 = LayerNorm(d_model=d_model)\n",
        "        self.layer_norm3 = LayerNorm(d_model=d_model)\n",
        "\n",
        "\n",
        "    def forward(self, x_out, x_enc, trg_mask, src_mask):\n",
        "        _x_out = x_out\n",
        "        x_out = self.mh_attn(q=x_out, k=x_out, v=x_out, mask=trg_mask)\n",
        "        x_out = self.layer_norm1(x_out + _x_out)\n",
        "        _x_out = x_out\n",
        "\n",
        "        if x_enc is not None:\n",
        "            x_out = self.enc_dec_attn(q=x_out, k=x_enc, v=x_enc, mask=src_mask)\n",
        "            x_out = self.layer_norm2(x_out + _x_out)\n",
        "\n",
        "        x_out = self.ffn(x_out)\n",
        "        x_out = self.layer_norm3(x_out)\n",
        "        return x_out\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, dec_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, device):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.emb = TransformerEmbedding(vocab_size=dec_voc_size, d_model=d_model, max_len=max_len, device=device)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(n_heads=n_head, d_model=d_model, hidden=ffn_hidden)\n",
        "                                     for _ in range(n_layers)])\n",
        "        self.linear = nn.Linear(d_model, dec_voc_size)\n",
        "\n",
        "    def forward(self, trg, src, trg_mask, src_mask):\n",
        "        x = self.emb(trg)  # Use embedded input\n",
        "        for layer in self.layers:\n",
        "            x = layer(x_out=x, x_enc=src, trg_mask=trg_mask, src_mask=src_mask)\n",
        "        return self.linear(x)\n",
        "\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, src_pad_idx, trg_pad_idx, trg_sos_idx, enc_voc_size, dec_voc_size, d_model, n_head, max_len,\n",
        "                 ffn_hidden, n_layers, device):\n",
        "        super().__init__()\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.trg_sos_idx = trg_sos_idx\n",
        "        self.device = device\n",
        "        self.encoder = Encoder(d_model=d_model,\n",
        "                               n_head=n_head,\n",
        "                               max_len=max_len,\n",
        "                               ffn_hidden=ffn_hidden,\n",
        "                               enc_voc_size=enc_voc_size,\n",
        "                               n_layers=n_layers,\n",
        "                               device=device)\n",
        "\n",
        "        self.decoder = Decoder(d_model=d_model,\n",
        "                               n_head=n_head,\n",
        "                               max_len=max_len,\n",
        "                               ffn_hidden=ffn_hidden,\n",
        "                               dec_voc_size=dec_voc_size,\n",
        "                               n_layers=n_layers,\n",
        "                               device=device)\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        output = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        return output\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        return src_mask\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(3)\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_sub_mask = torch.tril(torch.ones(trg_len, trg_len)).type(torch.ByteTensor).to(self.device)\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        return trg_mask"
      ],
      "metadata": {
        "trusted": true,
        "id": "duq1aqeR_VNg"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Config"
      ],
      "metadata": {
        "id": "j9YjHcij_VNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_content = \"\"\"training:\n",
        "  batch_size: 8\n",
        "  max_length: 128\n",
        "  epochs: 3\n",
        "  d_model: 512\n",
        "  n_heads: 8\n",
        "  vocab_size: 37000\n",
        "  shuffle: True\n",
        "  ffn_hidden: 2048\n",
        "  n_layers: 6\n",
        "  init_lr: 3e-5\n",
        "  weight_decay: 0.01\n",
        "  adam_eps: 1e-8\n",
        "  lr_scheduler:\n",
        "    factor: 0.5\n",
        "    patience: 3\n",
        "  data_percentage: 0.001\n",
        "\"\"\"\n",
        "dir_path = \"/kaggle/working/configs\"\n",
        "os.makedirs(dir_path, exist_ok=True)\n",
        "with open(\"/kaggle/working/configs/config.yaml\", \"w\") as f:\n",
        "    f.write(config_content)"
      ],
      "metadata": {
        "trusted": true,
        "id": "AI0kZPPO_VNh"
      },
      "outputs": [],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utils"
      ],
      "metadata": {
        "id": "sUC2O23g_VNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "def load_data(data_path, batch_size, tokenizer=None, shuffle=True, data_percentage=0.1):\n",
        "    train_pth = os.path.join(data_path, \"wmt14_translate_de-en_train.csv\")\n",
        "    test_pth = os.path.join(data_path, \"wmt14_translate_de-en_test.csv\")\n",
        "    val_pth = os.path.join(data_path, \"wmt14_translate_de-en_validation.csv\")\n",
        "\n",
        "    #load data\n",
        "    train_data = WMT14Dataset(csv_file=train_pth, src_lang=\"de\", tgt_lang=\"en\", tokenizer=tokenizer, data_percentage=data_percentage)\n",
        "    test_data = WMT14Dataset(csv_file=test_pth, src_lang=\"de\", tgt_lang=\"en\", tokenizer=tokenizer, data_percentage=data_percentage)\n",
        "    val_data = WMT14Dataset(csv_file=val_pth, src_lang=\"de\", tgt_lang=\"en\", tokenizer=tokenizer, data_percentage=data_percentage)\n",
        "    #data loaders\n",
        "    train_dl = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=shuffle)\n",
        "    test_dl = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=shuffle)\n",
        "    val_dl = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "    return train_dl, test_dl, val_dl\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "KhZE2-z5_VNi"
      },
      "outputs": [],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "eoVZ3JsH_VNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "@author : Hyunwoong\n",
        "@when : 2019-10-22\n",
        "@homepage : https://github.com/gusdnd852\n",
        "\"\"\"\n",
        "\n",
        "CONFIG_PATH = \"/kaggle/working/configs/config.yaml\"\n",
        "\n",
        "def load_config(config_path=CONFIG_PATH):\n",
        "    with open(config_path, 'r') as file:\n",
        "        return yaml.safe_load(file)\n",
        "\n",
        "config = load_config()\n",
        "BATCH_SIZE = int(config[\"training\"][\"batch_size\"])\n",
        "EPOCHS = int(config[\"training\"][\"epochs\"])\n",
        "MAX_LENGTH = int(config[\"training\"][\"max_length\"])\n",
        "SHUFFLE = bool(config[\"training\"][\"shuffle\"])\n",
        "D_MODEL = int(config[\"training\"][\"d_model\"])\n",
        "N_HEADS = int(config[\"training\"][\"n_heads\"])\n",
        "FFN_HIDDEN = int(config[\"training\"][\"ffn_hidden\"])\n",
        "N_LAYERS = int(config[\"training\"][\"n_layers\"])\n",
        "INIT_LR = float(config[\"training\"][\"init_lr\"])\n",
        "WEIGHT_DECAY = float(config[\"training\"][\"weight_decay\"])\n",
        "ADAM_EPS = float(config[\"training\"][\"adam_eps\"])\n",
        "LR_SCHEDULE_FACTOR = float(config[\"training\"][\"lr_scheduler\"][\"factor\"])\n",
        "LR_SCHEDULE_PATIENCE = int(config[\"training\"][\"lr_scheduler\"][\"patience\"])\n",
        "DATA_PERCENTAGE = float(config[\"training\"][\"data_percentage\"])\n",
        "\n",
        "\n",
        "DEVICE =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, (nn.Linear)):\n",
        "        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
        "tokenizer.add_special_tokens({'bos_token': '<bos>'})\n",
        "bos_token_id = tokenizer.convert_tokens_to_ids('<bos>')\n",
        "\n",
        "\n",
        "model = Transformer(src_pad_idx=tokenizer.pad_token_id,\n",
        "                    trg_pad_idx=tokenizer.pad_token_id,\n",
        "                    trg_sos_idx=bos_token_id,\n",
        "                    d_model=D_MODEL,\n",
        "                    enc_voc_size=len(tokenizer),\n",
        "                    dec_voc_size=len(tokenizer),\n",
        "                    max_len=MAX_LENGTH,\n",
        "                    ffn_hidden=FFN_HIDDEN,\n",
        "                    n_head=N_HEADS,\n",
        "                    n_layers=N_LAYERS,\n",
        "                    device=DEVICE).to(DEVICE)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "model.apply(initialize_weights)\n",
        "optimizer = Adam(params=model.parameters(),\n",
        "                 lr=INIT_LR,\n",
        "                 weight_decay=WEIGHT_DECAY,\n",
        "                 eps=ADAM_EPS)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                 verbose=True,\n",
        "                                                 factor=LR_SCHEDULE_FACTOR,\n",
        "                                                 patience=LR_SCHEDULE_PATIENCE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch[\"input_ids\"].to(DEVICE)\n",
        "        trg = batch[\"label\"].to(DEVICE)\n",
        "        decoded_src = tokenizer.decode(src[0], skip_special_tokens=True)\n",
        "        decoded_trg = tokenizer.decode(trg[0], skip_special_tokens=True)\n",
        "        #print(\"src----> \", decoded_src)\n",
        "        #print(\"trg-----> \", decoded_trg)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg[:, :-1])\n",
        "        output_reshape = output.contiguous().view(-1, output.shape[-1])\n",
        "        trg = trg[:, 1:].contiguous().view(-1)\n",
        "        #print(\"type op:: \", type(output_reshape))\n",
        "        #print(\"type op[0]::\", type(output_reshape[0]))\n",
        "        #print(\"type in type :: \", type(output_reshape[0][0]))\n",
        "        #print(output_reshape[0])\n",
        "        #decoded_op = tokenizer.decode(output_reshape[0], skip_special_tokens=True)\n",
        "        #print(\"decoded_op------> \", decoded_op)\n",
        "        #time.sleep(5)\n",
        "\n",
        "        loss = criterion(output_reshape, trg)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        print('step :', round((i / len(iterator)) * 100, 2), '% , loss :', loss.item())\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch[\"input_ids\"].to(DEVICE)\n",
        "            trg = batch[\"label\"].to(DEVICE)\n",
        "            output = model(src, trg[:, :-1])\n",
        "            output_reshape = output.contiguous().view(-1, output.shape[-1])\n",
        "            trg = trg[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            loss = criterion(output_reshape, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def run(total_epoch, train_iter, valid_iter, best_loss):\n",
        "    train_losses, test_losses, bleus = [], [], []\n",
        "    for step in range(total_epoch):\n",
        "        start_time = time.time()\n",
        "        train_loss = train(model, train_iter, optimizer, criterion)\n",
        "        valid_loss = evaluate(model, valid_iter, criterion)\n",
        "        end_time = time.time()\n",
        "\n",
        "        scheduler.step(valid_loss)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(valid_loss)\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "        if valid_loss < best_loss:\n",
        "            best_loss = valid_loss\n",
        "            torch.save(model.state_dict(), 'saved/model-{0}.pt'.format(valid_loss))\n",
        "\n",
        "        f = open('result/train_loss.txt', 'w')\n",
        "        f.write(str(train_losses))\n",
        "        f.close()\n",
        "\n",
        "        f = open('result/test_loss.txt', 'w')\n",
        "        f.write(str(test_losses))\n",
        "        f.close()\n",
        "\n",
        "        print(f'Epoch: {step + 1} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "        print(f'\\tVal Loss: {valid_loss:.3f} |  Val PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    data_path = \"/content/kaggle/input/\"\n",
        "\n",
        "    train_dl, test_dl, val_dl = load_data(data_path=data_path, tokenizer=tokenizer, batch_size=BATCH_SIZE, data_percentage=DATA_PERCENTAGE)\n",
        "    run(total_epoch=EPOCHS, train_iter=train_dl, valid_iter=val_dl, best_loss=math.inf)\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d6CCGIN_VNi",
        "outputId": "cc469466-5ac4-4fd0-9750-f91f9ceedecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 93,471,589 trainable parameters\n",
            "step : 0.0 % , loss : 11.536124229431152\n",
            "step : 0.18 % , loss : 11.249007225036621\n",
            "step : 0.35 % , loss : 11.001866340637207\n",
            "step : 0.53 % , loss : 10.949739456176758\n",
            "step : 0.71 % , loss : 10.594855308532715\n",
            "step : 0.89 % , loss : 10.283860206604004\n",
            "step : 1.06 % , loss : 10.225699424743652\n",
            "step : 1.24 % , loss : 10.01215934753418\n",
            "step : 1.42 % , loss : 10.238692283630371\n",
            "step : 1.6 % , loss : 9.635466575622559\n",
            "step : 1.77 % , loss : 9.324207305908203\n",
            "step : 1.95 % , loss : 9.373258590698242\n",
            "step : 2.13 % , loss : 9.538851737976074\n",
            "step : 2.3 % , loss : 9.560059547424316\n",
            "step : 2.48 % , loss : 9.278266906738281\n",
            "step : 2.66 % , loss : 9.461784362792969\n",
            "step : 2.84 % , loss : 8.921696662902832\n",
            "step : 3.01 % , loss : 9.453008651733398\n",
            "step : 3.19 % , loss : 9.219252586364746\n",
            "step : 3.37 % , loss : 9.121427536010742\n",
            "step : 3.55 % , loss : 9.15060806274414\n",
            "step : 3.72 % , loss : 9.608712196350098\n",
            "step : 3.9 % , loss : 8.753780364990234\n",
            "step : 4.08 % , loss : 9.013506889343262\n",
            "step : 4.26 % , loss : 8.705121040344238\n",
            "step : 4.43 % , loss : 8.862931251525879\n",
            "step : 4.61 % , loss : 9.084209442138672\n",
            "step : 4.79 % , loss : 9.001130104064941\n",
            "step : 4.96 % , loss : 8.532971382141113\n",
            "step : 5.14 % , loss : 8.647584915161133\n",
            "step : 5.32 % , loss : 8.80315113067627\n",
            "step : 5.5 % , loss : 8.958211898803711\n",
            "step : 5.67 % , loss : 8.685619354248047\n",
            "step : 5.85 % , loss : 8.817716598510742\n",
            "step : 6.03 % , loss : 8.700493812561035\n",
            "step : 6.21 % , loss : 8.784518241882324\n",
            "step : 6.38 % , loss : 8.863221168518066\n",
            "step : 6.56 % , loss : 9.082140922546387\n",
            "step : 6.74 % , loss : 8.713457107543945\n",
            "step : 6.91 % , loss : 8.668068885803223\n",
            "step : 7.09 % , loss : 8.64540958404541\n",
            "step : 7.27 % , loss : 8.464694023132324\n",
            "step : 7.45 % , loss : 8.471195220947266\n",
            "step : 7.62 % , loss : 8.694649696350098\n",
            "step : 7.8 % , loss : 8.962319374084473\n",
            "step : 7.98 % , loss : 8.450514793395996\n",
            "step : 8.16 % , loss : 8.457408905029297\n",
            "step : 8.33 % , loss : 8.583568572998047\n",
            "step : 8.51 % , loss : 8.725275039672852\n",
            "step : 8.69 % , loss : 8.830266952514648\n",
            "step : 8.87 % , loss : 8.736014366149902\n",
            "step : 9.04 % , loss : 8.704137802124023\n",
            "step : 9.22 % , loss : 8.663851737976074\n",
            "step : 9.4 % , loss : 8.54236125946045\n",
            "step : 9.57 % , loss : 8.802872657775879\n",
            "step : 9.75 % , loss : 8.74375057220459\n",
            "step : 9.93 % , loss : 8.47060489654541\n",
            "step : 10.11 % , loss : 8.62303352355957\n",
            "step : 10.28 % , loss : 8.74551010131836\n",
            "step : 10.46 % , loss : 8.756467819213867\n",
            "step : 10.64 % , loss : 8.571633338928223\n",
            "step : 10.82 % , loss : 8.52166748046875\n",
            "step : 10.99 % , loss : 8.405845642089844\n",
            "step : 11.17 % , loss : 8.062394142150879\n",
            "step : 11.35 % , loss : 8.235512733459473\n",
            "step : 11.52 % , loss : 8.314586639404297\n",
            "step : 11.7 % , loss : 8.957186698913574\n",
            "step : 11.88 % , loss : 8.318623542785645\n",
            "step : 12.06 % , loss : 8.164998054504395\n",
            "step : 12.23 % , loss : 8.44410514831543\n",
            "step : 12.41 % , loss : 8.670724868774414\n",
            "step : 12.59 % , loss : 8.369486808776855\n",
            "step : 12.77 % , loss : 7.877373218536377\n",
            "step : 12.94 % , loss : 8.412253379821777\n",
            "step : 13.12 % , loss : 8.695005416870117\n",
            "step : 13.3 % , loss : 8.238866806030273\n",
            "step : 13.48 % , loss : 8.199471473693848\n",
            "step : 13.65 % , loss : 8.356888771057129\n",
            "step : 13.83 % , loss : 8.26391887664795\n",
            "step : 14.01 % , loss : 8.49681568145752\n",
            "step : 14.18 % , loss : 8.25538444519043\n",
            "step : 14.36 % , loss : 8.494161605834961\n",
            "step : 14.54 % , loss : 8.413945198059082\n",
            "step : 14.72 % , loss : 8.663629531860352\n",
            "step : 14.89 % , loss : 8.303667068481445\n",
            "step : 15.07 % , loss : 7.909946441650391\n",
            "step : 15.25 % , loss : 8.675036430358887\n",
            "step : 15.43 % , loss : 8.485669136047363\n",
            "step : 15.6 % , loss : 8.207173347473145\n",
            "step : 15.78 % , loss : 8.117544174194336\n",
            "step : 15.96 % , loss : 8.476449012756348\n",
            "step : 16.13 % , loss : 8.490730285644531\n",
            "step : 16.31 % , loss : 8.606766700744629\n",
            "step : 16.49 % , loss : 8.681987762451172\n",
            "step : 16.67 % , loss : 8.37767219543457\n",
            "step : 16.84 % , loss : 8.281563758850098\n",
            "step : 17.02 % , loss : 7.876110553741455\n",
            "step : 17.2 % , loss : 8.567117691040039\n",
            "step : 17.38 % , loss : 8.381230354309082\n",
            "step : 17.55 % , loss : 7.991774559020996\n",
            "step : 17.73 % , loss : 8.072643280029297\n",
            "step : 17.91 % , loss : 8.38409423828125\n",
            "step : 18.09 % , loss : 7.86868143081665\n",
            "step : 18.26 % , loss : 8.256017684936523\n",
            "step : 18.44 % , loss : 8.198098182678223\n",
            "step : 18.62 % , loss : 8.366581916809082\n",
            "step : 18.79 % , loss : 8.1368989944458\n",
            "step : 18.97 % , loss : 8.461543083190918\n",
            "step : 19.15 % , loss : 8.255173683166504\n",
            "step : 19.33 % , loss : 8.250443458557129\n",
            "step : 19.5 % , loss : 8.062333106994629\n",
            "step : 19.68 % , loss : 8.424322128295898\n",
            "step : 19.86 % , loss : 8.418413162231445\n",
            "step : 20.04 % , loss : 8.37465763092041\n",
            "step : 20.21 % , loss : 7.927315711975098\n",
            "step : 20.39 % , loss : 8.328609466552734\n",
            "step : 20.57 % , loss : 8.504570007324219\n",
            "step : 20.74 % , loss : 8.088213920593262\n",
            "step : 20.92 % , loss : 7.960788249969482\n",
            "step : 21.1 % , loss : 8.44770336151123\n",
            "step : 21.28 % , loss : 8.01246452331543\n",
            "step : 21.45 % , loss : 7.740084171295166\n",
            "step : 21.63 % , loss : 8.368757247924805\n",
            "step : 21.81 % , loss : 8.113829612731934\n",
            "step : 21.99 % , loss : 8.143298149108887\n",
            "step : 22.16 % , loss : 8.124882698059082\n",
            "step : 22.34 % , loss : 8.35799789428711\n",
            "step : 22.52 % , loss : 8.577041625976562\n",
            "step : 22.7 % , loss : 8.258352279663086\n",
            "step : 22.87 % , loss : 8.115245819091797\n",
            "step : 23.05 % , loss : 8.271322250366211\n",
            "step : 23.23 % , loss : 8.657363891601562\n",
            "step : 23.4 % , loss : 8.013669967651367\n",
            "step : 23.58 % , loss : 8.177077293395996\n",
            "step : 23.76 % , loss : 8.073309898376465\n",
            "step : 23.94 % , loss : 7.853003025054932\n",
            "step : 24.11 % , loss : 7.97939920425415\n",
            "step : 24.29 % , loss : 8.143087387084961\n",
            "step : 24.47 % , loss : 7.9712114334106445\n",
            "step : 24.65 % , loss : 8.23820972442627\n",
            "step : 24.82 % , loss : 7.769944667816162\n",
            "step : 25.0 % , loss : 7.842191219329834\n",
            "step : 25.18 % , loss : 8.144438743591309\n",
            "step : 25.35 % , loss : 8.223569869995117\n",
            "step : 25.53 % , loss : 8.683934211730957\n",
            "step : 25.71 % , loss : 8.275174140930176\n",
            "step : 25.89 % , loss : 8.14828109741211\n",
            "step : 26.06 % , loss : 8.309025764465332\n",
            "step : 26.24 % , loss : 8.369790077209473\n",
            "step : 26.42 % , loss : 8.51759147644043\n",
            "step : 26.6 % , loss : 7.892254829406738\n",
            "step : 26.77 % , loss : 8.3789701461792\n",
            "step : 26.95 % , loss : 8.50086498260498\n",
            "step : 27.13 % , loss : 8.187413215637207\n",
            "step : 27.3 % , loss : 8.376775741577148\n",
            "step : 27.48 % , loss : 8.486583709716797\n",
            "step : 27.66 % , loss : 8.217666625976562\n",
            "step : 27.84 % , loss : 8.042813301086426\n",
            "step : 28.01 % , loss : 8.104277610778809\n",
            "step : 28.19 % , loss : 8.272834777832031\n",
            "step : 28.37 % , loss : 7.915546894073486\n",
            "step : 28.55 % , loss : 7.786649703979492\n",
            "step : 28.72 % , loss : 7.835161209106445\n",
            "step : 28.9 % , loss : 8.349824905395508\n",
            "step : 29.08 % , loss : 8.620041847229004\n",
            "step : 29.26 % , loss : 7.993404388427734\n",
            "step : 29.43 % , loss : 7.88362979888916\n",
            "step : 29.61 % , loss : 8.197189331054688\n",
            "step : 29.79 % , loss : 7.846692085266113\n",
            "step : 29.96 % , loss : 8.395797729492188\n",
            "step : 30.14 % , loss : 7.94386625289917\n",
            "step : 30.32 % , loss : 7.9334797859191895\n",
            "step : 30.5 % , loss : 7.984598159790039\n",
            "step : 30.67 % , loss : 7.921148777008057\n",
            "step : 30.85 % , loss : 8.562566757202148\n",
            "step : 31.03 % , loss : 8.009223937988281\n",
            "step : 31.21 % , loss : 8.00380802154541\n",
            "step : 31.38 % , loss : 7.590198993682861\n",
            "step : 31.56 % , loss : 8.219919204711914\n",
            "step : 31.74 % , loss : 8.146523475646973\n",
            "step : 31.91 % , loss : 7.885237693786621\n",
            "step : 32.09 % , loss : 7.822948932647705\n",
            "step : 32.27 % , loss : 8.116456031799316\n",
            "step : 32.45 % , loss : 8.393168449401855\n",
            "step : 32.62 % , loss : 8.356917381286621\n",
            "step : 32.8 % , loss : 7.825159549713135\n",
            "step : 32.98 % , loss : 8.221023559570312\n",
            "step : 33.16 % , loss : 8.336348533630371\n",
            "step : 33.33 % , loss : 8.029988288879395\n",
            "step : 33.51 % , loss : 8.144137382507324\n",
            "step : 33.69 % , loss : 7.975823402404785\n",
            "step : 33.87 % , loss : 8.074654579162598\n",
            "step : 34.04 % , loss : 8.041966438293457\n",
            "step : 34.22 % , loss : 8.417763710021973\n",
            "step : 34.4 % , loss : 8.436712265014648\n",
            "step : 34.57 % , loss : 7.774059295654297\n",
            "step : 34.75 % , loss : 8.155877113342285\n",
            "step : 34.93 % , loss : 7.847444534301758\n",
            "step : 35.11 % , loss : 7.8556952476501465\n",
            "step : 35.28 % , loss : 7.734124183654785\n",
            "step : 35.46 % , loss : 7.829071044921875\n",
            "step : 35.64 % , loss : 7.928281307220459\n",
            "step : 35.82 % , loss : 8.187552452087402\n",
            "step : 35.99 % , loss : 7.909890651702881\n",
            "step : 36.17 % , loss : 8.206924438476562\n",
            "step : 36.35 % , loss : 8.252713203430176\n",
            "step : 36.52 % , loss : 8.445866584777832\n",
            "step : 36.7 % , loss : 8.185271263122559\n",
            "step : 36.88 % , loss : 8.5238037109375\n",
            "step : 37.06 % , loss : 8.063058853149414\n",
            "step : 37.23 % , loss : 7.963681221008301\n",
            "step : 37.41 % , loss : 7.753612995147705\n",
            "step : 37.59 % , loss : 7.7440643310546875\n",
            "step : 37.77 % , loss : 7.970444679260254\n",
            "step : 37.94 % , loss : 8.201868057250977\n",
            "step : 38.12 % , loss : 7.984899997711182\n",
            "step : 38.3 % , loss : 8.58436393737793\n",
            "step : 38.48 % , loss : 7.924137592315674\n",
            "step : 38.65 % , loss : 8.558418273925781\n",
            "step : 38.83 % , loss : 7.997696399688721\n",
            "step : 39.01 % , loss : 7.893075942993164\n",
            "step : 39.18 % , loss : 8.235152244567871\n",
            "step : 39.36 % , loss : 7.897463321685791\n",
            "step : 39.54 % , loss : 7.863924503326416\n",
            "step : 39.72 % , loss : 8.182646751403809\n",
            "step : 39.89 % , loss : 8.403481483459473\n",
            "step : 40.07 % , loss : 7.4749040603637695\n",
            "step : 40.25 % , loss : 7.762673377990723\n",
            "step : 40.43 % , loss : 7.863424301147461\n",
            "step : 40.6 % , loss : 8.126983642578125\n",
            "step : 40.78 % , loss : 7.768357753753662\n",
            "step : 40.96 % , loss : 7.609129905700684\n",
            "step : 41.13 % , loss : 7.934943199157715\n",
            "step : 41.31 % , loss : 8.489263534545898\n",
            "step : 41.49 % , loss : 7.891151428222656\n",
            "step : 41.67 % , loss : 7.539140701293945\n",
            "step : 41.84 % , loss : 8.912840843200684\n",
            "step : 42.02 % , loss : 7.8998122215271\n",
            "step : 42.2 % , loss : 7.927393436431885\n",
            "step : 42.38 % , loss : 7.684257507324219\n",
            "step : 42.55 % , loss : 7.757967948913574\n",
            "step : 42.73 % , loss : 7.994922161102295\n",
            "step : 42.91 % , loss : 8.071221351623535\n",
            "step : 43.09 % , loss : 8.142267227172852\n",
            "step : 43.26 % , loss : 7.954891204833984\n",
            "step : 43.44 % , loss : 8.127371788024902\n",
            "step : 43.62 % , loss : 7.967684268951416\n",
            "step : 43.79 % , loss : 8.111489295959473\n",
            "step : 43.97 % , loss : 7.950155735015869\n",
            "step : 44.15 % , loss : 7.9100565910339355\n",
            "step : 44.33 % , loss : 7.8539252281188965\n",
            "step : 44.5 % , loss : 7.660170078277588\n",
            "step : 44.68 % , loss : 8.009594917297363\n",
            "step : 44.86 % , loss : 7.895561218261719\n",
            "step : 45.04 % , loss : 8.164581298828125\n",
            "step : 45.21 % , loss : 7.858739376068115\n",
            "step : 45.39 % , loss : 8.303933143615723\n",
            "step : 45.57 % , loss : 7.966158390045166\n",
            "step : 45.74 % , loss : 8.115528106689453\n",
            "step : 45.92 % , loss : 7.797913074493408\n",
            "step : 46.1 % , loss : 8.147719383239746\n",
            "step : 46.28 % , loss : 7.499818325042725\n",
            "step : 46.45 % , loss : 7.888958930969238\n",
            "step : 46.63 % , loss : 7.649672031402588\n",
            "step : 46.81 % , loss : 8.202204704284668\n",
            "step : 46.99 % , loss : 8.430694580078125\n",
            "step : 47.16 % , loss : 7.93505334854126\n",
            "step : 47.34 % , loss : 7.9606428146362305\n",
            "step : 47.52 % , loss : 8.16429328918457\n",
            "step : 47.7 % , loss : 8.29224681854248\n",
            "step : 47.87 % , loss : 8.088180541992188\n",
            "step : 48.05 % , loss : 7.866514205932617\n",
            "step : 48.23 % , loss : 7.895426273345947\n",
            "step : 48.4 % , loss : 7.623497009277344\n",
            "step : 48.58 % , loss : 7.933810234069824\n",
            "step : 48.76 % , loss : 7.9856462478637695\n",
            "step : 48.94 % , loss : 7.66127872467041\n",
            "step : 49.11 % , loss : 8.051525115966797\n",
            "step : 49.29 % , loss : 7.6747026443481445\n",
            "step : 49.47 % , loss : 7.701826572418213\n",
            "step : 49.65 % , loss : 7.59864616394043\n",
            "step : 49.82 % , loss : 7.692381858825684\n",
            "step : 50.0 % , loss : 7.692150592803955\n",
            "step : 50.18 % , loss : 7.7143707275390625\n",
            "step : 50.35 % , loss : 7.250054836273193\n",
            "step : 50.53 % , loss : 7.722339630126953\n",
            "step : 50.71 % , loss : 7.728512287139893\n",
            "step : 50.89 % , loss : 7.977938652038574\n",
            "step : 51.06 % , loss : 7.9077653884887695\n",
            "step : 51.24 % , loss : 7.882253170013428\n",
            "step : 51.42 % , loss : 8.075644493103027\n",
            "step : 51.6 % , loss : 8.051534652709961\n",
            "step : 51.77 % , loss : 7.841827392578125\n",
            "step : 51.95 % , loss : 7.725392818450928\n",
            "step : 52.13 % , loss : 7.679753303527832\n",
            "step : 52.3 % , loss : 7.915131092071533\n",
            "step : 52.48 % , loss : 7.5818963050842285\n",
            "step : 52.66 % , loss : 7.753078937530518\n",
            "step : 52.84 % , loss : 7.504791736602783\n",
            "step : 53.01 % , loss : 7.941494941711426\n",
            "step : 53.19 % , loss : 7.895383358001709\n",
            "step : 53.37 % , loss : 7.801379680633545\n",
            "step : 53.55 % , loss : 7.610535621643066\n",
            "step : 53.72 % , loss : 8.052555084228516\n",
            "step : 53.9 % , loss : 7.917691230773926\n",
            "step : 54.08 % , loss : 8.041780471801758\n",
            "step : 54.26 % , loss : 7.37855863571167\n",
            "step : 54.43 % , loss : 7.951083183288574\n",
            "step : 54.61 % , loss : 7.66759729385376\n",
            "step : 54.79 % , loss : 7.88004732131958\n",
            "step : 54.96 % , loss : 7.786484241485596\n",
            "step : 55.14 % , loss : 8.001592636108398\n",
            "step : 55.32 % , loss : 8.505559921264648\n",
            "step : 55.5 % , loss : 7.761316776275635\n",
            "step : 55.67 % , loss : 7.808762073516846\n",
            "step : 55.85 % , loss : 7.827914237976074\n",
            "step : 56.03 % , loss : 7.721419811248779\n",
            "step : 56.21 % , loss : 8.017741203308105\n",
            "step : 56.38 % , loss : 7.875560760498047\n",
            "step : 56.56 % , loss : 7.72326135635376\n",
            "step : 56.74 % , loss : 7.607156753540039\n",
            "step : 56.91 % , loss : 7.730453014373779\n",
            "step : 57.09 % , loss : 7.800738334655762\n",
            "step : 57.27 % , loss : 7.825797080993652\n",
            "step : 57.45 % , loss : 7.850170135498047\n",
            "step : 57.62 % , loss : 7.650863170623779\n",
            "step : 57.8 % , loss : 8.093626976013184\n",
            "step : 57.98 % , loss : 8.10301685333252\n",
            "step : 58.16 % , loss : 7.768036365509033\n",
            "step : 58.33 % , loss : 7.837767124176025\n",
            "step : 58.51 % , loss : 7.803760528564453\n",
            "step : 58.69 % , loss : 8.134500503540039\n",
            "step : 58.87 % , loss : 7.960224628448486\n",
            "step : 59.04 % , loss : 7.556032657623291\n",
            "step : 59.22 % , loss : 7.64642333984375\n",
            "step : 59.4 % , loss : 7.826201915740967\n",
            "step : 59.57 % , loss : 7.732274532318115\n",
            "step : 59.75 % , loss : 8.053403854370117\n",
            "step : 59.93 % , loss : 7.742090225219727\n",
            "step : 60.11 % , loss : 7.705163478851318\n",
            "step : 60.28 % , loss : 7.585409164428711\n",
            "step : 60.46 % , loss : 7.737788677215576\n",
            "step : 60.64 % , loss : 7.719220161437988\n",
            "step : 60.82 % , loss : 7.908383846282959\n",
            "step : 60.99 % , loss : 7.871436595916748\n",
            "step : 61.17 % , loss : 7.504545211791992\n",
            "step : 61.35 % , loss : 7.458585739135742\n",
            "step : 61.52 % , loss : 7.744567394256592\n",
            "step : 61.7 % , loss : 7.708213806152344\n",
            "step : 61.88 % , loss : 7.643604278564453\n",
            "step : 62.06 % , loss : 7.514927864074707\n",
            "step : 62.23 % , loss : 7.733607769012451\n",
            "step : 62.41 % , loss : 7.425605773925781\n",
            "step : 62.59 % , loss : 7.615304946899414\n",
            "step : 62.77 % , loss : 7.873992443084717\n",
            "step : 62.94 % , loss : 7.929623126983643\n",
            "step : 63.12 % , loss : 7.757820129394531\n",
            "step : 63.3 % , loss : 8.1937255859375\n",
            "step : 63.48 % , loss : 7.53331184387207\n",
            "step : 63.65 % , loss : 7.702498435974121\n",
            "step : 63.83 % , loss : 7.90756368637085\n",
            "step : 64.01 % , loss : 7.631679534912109\n",
            "step : 64.18 % , loss : 7.691736221313477\n",
            "step : 64.36 % , loss : 7.429198741912842\n",
            "step : 64.54 % , loss : 7.578863620758057\n",
            "step : 64.72 % , loss : 7.62726354598999\n",
            "step : 64.89 % , loss : 7.294826030731201\n",
            "step : 65.07 % , loss : 7.480893135070801\n",
            "step : 65.25 % , loss : 7.489572048187256\n",
            "step : 65.43 % , loss : 7.922628879547119\n",
            "step : 65.6 % , loss : 7.997354507446289\n",
            "step : 65.78 % , loss : 7.509971618652344\n",
            "step : 65.96 % , loss : 7.918764114379883\n",
            "step : 66.13 % , loss : 7.647425651550293\n",
            "step : 66.31 % , loss : 7.823604583740234\n",
            "step : 66.49 % , loss : 8.236586570739746\n",
            "step : 66.67 % , loss : 7.364329814910889\n",
            "step : 66.84 % , loss : 7.852746963500977\n",
            "step : 67.02 % , loss : 8.066850662231445\n",
            "step : 67.2 % , loss : 7.290714263916016\n",
            "step : 67.38 % , loss : 7.884347915649414\n",
            "step : 67.55 % , loss : 7.4870829582214355\n",
            "step : 67.73 % , loss : 7.8484206199646\n",
            "step : 67.91 % , loss : 7.937460899353027\n",
            "step : 68.09 % , loss : 7.4186882972717285\n",
            "step : 68.26 % , loss : 7.998859405517578\n",
            "step : 68.44 % , loss : 7.723315238952637\n",
            "step : 68.62 % , loss : 7.576604843139648\n",
            "step : 68.79 % , loss : 7.833698749542236\n",
            "step : 68.97 % , loss : 7.660037517547607\n",
            "step : 69.15 % , loss : 7.717839241027832\n",
            "step : 69.33 % , loss : 7.557145595550537\n",
            "step : 69.5 % , loss : 7.710210800170898\n",
            "step : 69.68 % , loss : 7.713382720947266\n",
            "step : 69.86 % , loss : 7.6760663986206055\n",
            "step : 70.04 % , loss : 7.9495439529418945\n",
            "step : 70.21 % , loss : 7.744919300079346\n",
            "step : 70.39 % , loss : 7.518649578094482\n",
            "step : 70.57 % , loss : 7.698516368865967\n",
            "step : 70.74 % , loss : 7.660646438598633\n",
            "step : 70.92 % , loss : 8.011758804321289\n",
            "step : 71.1 % , loss : 7.645358562469482\n",
            "step : 71.28 % , loss : 7.280582904815674\n",
            "step : 71.45 % , loss : 7.677867889404297\n",
            "step : 71.63 % , loss : 7.68065881729126\n",
            "step : 71.81 % , loss : 7.691302299499512\n",
            "step : 71.99 % , loss : 7.377719402313232\n",
            "step : 72.16 % , loss : 7.535580158233643\n",
            "step : 72.34 % , loss : 7.87711238861084\n",
            "step : 72.52 % , loss : 7.651797771453857\n",
            "step : 72.7 % , loss : 7.689990997314453\n",
            "step : 72.87 % , loss : 7.705682277679443\n",
            "step : 73.05 % , loss : 7.851802825927734\n",
            "step : 73.23 % , loss : 7.302831649780273\n",
            "step : 73.4 % , loss : 7.543231964111328\n",
            "step : 73.58 % , loss : 7.520548343658447\n",
            "step : 73.76 % , loss : 7.487978935241699\n",
            "step : 73.94 % , loss : 7.73228645324707\n",
            "step : 74.11 % , loss : 7.677933692932129\n",
            "step : 74.29 % , loss : 7.572597980499268\n",
            "step : 74.47 % , loss : 7.904070854187012\n",
            "step : 74.65 % , loss : 7.785482406616211\n",
            "step : 74.82 % , loss : 8.002245903015137\n",
            "step : 75.0 % , loss : 7.646546363830566\n",
            "step : 75.18 % , loss : 7.460431098937988\n",
            "step : 75.35 % , loss : 7.551361083984375\n",
            "step : 75.53 % , loss : 8.051188468933105\n",
            "step : 75.71 % , loss : 7.580623626708984\n",
            "step : 75.89 % , loss : 7.403449058532715\n",
            "step : 76.06 % , loss : 7.784021377563477\n",
            "step : 76.24 % , loss : 7.379522323608398\n",
            "step : 76.42 % , loss : 7.956952095031738\n",
            "step : 76.6 % , loss : 7.789565086364746\n",
            "step : 76.77 % , loss : 8.462567329406738\n",
            "step : 76.95 % , loss : 7.577572822570801\n",
            "step : 77.13 % , loss : 7.848505973815918\n",
            "step : 77.3 % , loss : 7.931715488433838\n",
            "step : 77.48 % , loss : 7.495154857635498\n",
            "step : 77.66 % , loss : 7.702432632446289\n",
            "step : 77.84 % , loss : 7.7417311668396\n",
            "step : 78.01 % , loss : 7.5126543045043945\n",
            "step : 78.19 % , loss : 7.354954242706299\n",
            "step : 78.37 % , loss : 7.458461761474609\n",
            "step : 78.55 % , loss : 7.778292179107666\n",
            "step : 78.72 % , loss : 7.569713115692139\n",
            "step : 78.9 % , loss : 7.728397846221924\n",
            "step : 79.08 % , loss : 7.605658531188965\n",
            "step : 79.26 % , loss : 7.683974266052246\n",
            "step : 79.43 % , loss : 7.304459095001221\n",
            "step : 79.61 % , loss : 7.779420375823975\n",
            "step : 79.79 % , loss : 7.972469806671143\n",
            "step : 79.96 % , loss : 8.165757179260254\n",
            "step : 80.14 % , loss : 7.593944072723389\n",
            "step : 80.32 % , loss : 7.337516784667969\n",
            "step : 80.5 % , loss : 7.930980205535889\n",
            "step : 80.67 % , loss : 7.434354782104492\n",
            "step : 80.85 % , loss : 8.05610179901123\n",
            "step : 81.03 % , loss : 7.574193954467773\n",
            "step : 81.21 % , loss : 7.899282932281494\n",
            "step : 81.38 % , loss : 7.751288414001465\n",
            "step : 81.56 % , loss : 7.747483730316162\n",
            "step : 81.74 % , loss : 7.722769260406494\n",
            "step : 81.91 % , loss : 7.538394927978516\n",
            "step : 82.09 % , loss : 7.50956916809082\n",
            "step : 82.27 % , loss : 7.529806137084961\n",
            "step : 82.45 % , loss : 7.54691219329834\n",
            "step : 82.62 % , loss : 7.5774827003479\n",
            "step : 82.8 % , loss : 7.429229736328125\n",
            "step : 82.98 % , loss : 7.638622760772705\n",
            "step : 83.16 % , loss : 7.622305393218994\n",
            "step : 83.33 % , loss : 7.360136985778809\n",
            "step : 83.51 % , loss : 7.246976375579834\n",
            "step : 83.69 % , loss : 7.49761438369751\n",
            "step : 83.87 % , loss : 7.706151485443115\n",
            "step : 84.04 % , loss : 7.833662033081055\n",
            "step : 84.22 % , loss : 7.416279315948486\n",
            "step : 84.4 % , loss : 7.843840599060059\n",
            "step : 84.57 % , loss : 7.344135761260986\n",
            "step : 84.75 % , loss : 7.660269260406494\n",
            "step : 84.93 % , loss : 7.609055995941162\n",
            "step : 85.11 % , loss : 7.278817653656006\n",
            "step : 85.28 % , loss : 7.054495334625244\n",
            "step : 85.46 % , loss : 7.401601791381836\n",
            "step : 85.64 % , loss : 7.5390944480896\n",
            "step : 85.82 % , loss : 7.974986553192139\n",
            "step : 85.99 % , loss : 7.515099048614502\n",
            "step : 86.17 % , loss : 7.557487487792969\n",
            "step : 86.35 % , loss : 7.875702857971191\n",
            "step : 86.52 % , loss : 7.452669143676758\n",
            "step : 86.7 % , loss : 7.5097761154174805\n",
            "step : 86.88 % , loss : 7.972419261932373\n",
            "step : 87.06 % , loss : 7.610015392303467\n",
            "step : 87.23 % , loss : 7.469799518585205\n",
            "step : 87.41 % , loss : 7.127577304840088\n",
            "step : 87.59 % , loss : 7.9141411781311035\n",
            "step : 87.77 % , loss : 7.3297319412231445\n",
            "step : 87.94 % , loss : 7.529105186462402\n",
            "step : 88.12 % , loss : 7.414452075958252\n",
            "step : 88.3 % , loss : 7.554319858551025\n",
            "step : 88.48 % , loss : 7.2062273025512695\n",
            "step : 88.65 % , loss : 7.533464431762695\n",
            "step : 88.83 % , loss : 7.247053623199463\n",
            "step : 89.01 % , loss : 7.571178913116455\n",
            "step : 89.18 % , loss : 7.665975570678711\n",
            "step : 89.36 % , loss : 7.906524181365967\n",
            "step : 89.54 % , loss : 7.236527442932129\n",
            "step : 89.72 % , loss : 7.542837619781494\n",
            "step : 89.89 % , loss : 7.767202854156494\n",
            "step : 90.07 % , loss : 7.649838924407959\n",
            "step : 90.25 % , loss : 7.677323818206787\n",
            "step : 90.43 % , loss : 8.030241966247559\n",
            "step : 90.6 % , loss : 7.5097527503967285\n",
            "step : 90.78 % , loss : 7.744447708129883\n",
            "step : 90.96 % , loss : 7.379202842712402\n",
            "step : 91.13 % , loss : 7.481720447540283\n",
            "step : 91.31 % , loss : 7.434928894042969\n",
            "step : 91.49 % , loss : 7.279069900512695\n",
            "step : 91.67 % , loss : 7.623716831207275\n",
            "step : 91.84 % , loss : 7.382681846618652\n",
            "step : 92.02 % , loss : 7.371355056762695\n",
            "step : 92.2 % , loss : 7.414178371429443\n",
            "step : 92.38 % , loss : 7.614912986755371\n",
            "step : 92.55 % , loss : 7.696810722351074\n",
            "step : 92.73 % , loss : 7.774170398712158\n",
            "step : 92.91 % , loss : 7.542764663696289\n",
            "step : 93.09 % , loss : 7.483273983001709\n",
            "step : 93.26 % , loss : 7.658366680145264\n",
            "step : 93.44 % , loss : 7.607565402984619\n",
            "step : 93.62 % , loss : 7.3912177085876465\n",
            "step : 93.79 % , loss : 7.443192005157471\n",
            "step : 93.97 % , loss : 7.527226448059082\n",
            "step : 94.15 % , loss : 7.044174671173096\n",
            "step : 94.33 % , loss : 7.704497814178467\n",
            "step : 94.5 % , loss : 7.7523603439331055\n",
            "step : 94.68 % , loss : 7.459601879119873\n",
            "step : 94.86 % , loss : 7.716920375823975\n",
            "step : 95.04 % , loss : 7.827361106872559\n",
            "step : 95.21 % , loss : 7.7121381759643555\n",
            "step : 95.39 % , loss : 7.4033331871032715\n",
            "step : 95.57 % , loss : 7.612667560577393\n",
            "step : 95.74 % , loss : 7.4196672439575195\n",
            "step : 95.92 % , loss : 7.396391868591309\n",
            "step : 96.1 % , loss : 7.438567161560059\n",
            "step : 96.28 % , loss : 7.413649082183838\n",
            "step : 96.45 % , loss : 7.644668102264404\n",
            "step : 96.63 % , loss : 7.343080997467041\n",
            "step : 96.81 % , loss : 7.56766414642334\n",
            "step : 96.99 % , loss : 7.815277099609375\n",
            "step : 97.16 % , loss : 7.66216516494751\n",
            "step : 97.34 % , loss : 7.1285576820373535\n",
            "step : 97.52 % , loss : 7.406427383422852\n",
            "step : 97.7 % , loss : 7.424866676330566\n",
            "step : 97.87 % , loss : 7.136321067810059\n",
            "step : 98.05 % , loss : 7.522965431213379\n",
            "step : 98.23 % , loss : 7.000124454498291\n",
            "step : 98.4 % , loss : 7.487524032592773\n",
            "step : 98.58 % , loss : 7.575515270233154\n",
            "step : 98.76 % , loss : 7.405117511749268\n",
            "step : 98.94 % , loss : 7.600681304931641\n",
            "step : 99.11 % , loss : 7.55020809173584\n",
            "step : 99.29 % , loss : 7.3650946617126465\n",
            "step : 99.47 % , loss : 7.152951240539551\n",
            "step : 99.65 % , loss : 7.356470108032227\n",
            "step : 99.82 % , loss : 7.348129749298096\n",
            "Epoch: 1 | Time: 5m 37s\n",
            "\tTrain Loss: 8.003 | Train PPL: 2991.120\n",
            "\tVal Loss: 7.468 |  Val PPL: 1750.624\n",
            "step : 0.0 % , loss : 7.838904857635498\n",
            "step : 0.18 % , loss : 7.538308620452881\n",
            "step : 0.35 % , loss : 7.4499897956848145\n",
            "step : 0.53 % , loss : 7.793267250061035\n",
            "step : 0.71 % , loss : 7.303865909576416\n",
            "step : 0.89 % , loss : 7.194383144378662\n",
            "step : 1.06 % , loss : 7.589478969573975\n",
            "step : 1.24 % , loss : 7.256827354431152\n",
            "step : 1.42 % , loss : 8.213210105895996\n",
            "step : 1.6 % , loss : 7.941357612609863\n",
            "step : 1.77 % , loss : 7.5555620193481445\n",
            "step : 1.95 % , loss : 7.31719446182251\n",
            "step : 2.13 % , loss : 7.257474422454834\n",
            "step : 2.3 % , loss : 7.344243049621582\n",
            "step : 2.48 % , loss : 7.315003871917725\n",
            "step : 2.66 % , loss : 7.424849033355713\n",
            "step : 2.84 % , loss : 7.218916893005371\n",
            "step : 3.01 % , loss : 7.254122257232666\n",
            "step : 3.19 % , loss : 7.248380184173584\n",
            "step : 3.37 % , loss : 7.523748874664307\n",
            "step : 3.55 % , loss : 7.139886856079102\n",
            "step : 3.72 % , loss : 7.408386707305908\n",
            "step : 3.9 % , loss : 7.682727336883545\n",
            "step : 4.08 % , loss : 7.541168689727783\n",
            "step : 4.26 % , loss : 7.166248321533203\n",
            "step : 4.43 % , loss : 7.575340270996094\n",
            "step : 4.61 % , loss : 7.6996235847473145\n",
            "step : 4.79 % , loss : 7.428984642028809\n",
            "step : 4.96 % , loss : 7.781978130340576\n",
            "step : 5.14 % , loss : 7.921166896820068\n",
            "step : 5.32 % , loss : 7.504262447357178\n",
            "step : 5.5 % , loss : 7.589656829833984\n",
            "step : 5.67 % , loss : 7.358112335205078\n",
            "step : 5.85 % , loss : 7.501471996307373\n",
            "step : 6.03 % , loss : 7.600793838500977\n",
            "step : 6.21 % , loss : 7.185822486877441\n",
            "step : 6.38 % , loss : 7.300840377807617\n",
            "step : 6.56 % , loss : 6.838965892791748\n",
            "step : 6.74 % , loss : 7.567468643188477\n",
            "step : 6.91 % , loss : 7.147817134857178\n",
            "step : 7.09 % , loss : 7.5681376457214355\n",
            "step : 7.27 % , loss : 7.357329845428467\n",
            "step : 7.45 % , loss : 7.151235103607178\n",
            "step : 7.62 % , loss : 7.628445625305176\n",
            "step : 7.8 % , loss : 7.5991363525390625\n",
            "step : 7.98 % , loss : 7.914371490478516\n",
            "step : 8.16 % , loss : 7.104730129241943\n",
            "step : 8.33 % , loss : 7.615847110748291\n",
            "step : 8.51 % , loss : 7.131726264953613\n",
            "step : 8.69 % , loss : 7.931784152984619\n",
            "step : 8.87 % , loss : 7.483901500701904\n",
            "step : 9.04 % , loss : 7.554201126098633\n",
            "step : 9.22 % , loss : 7.349900722503662\n",
            "step : 9.4 % , loss : 7.505575180053711\n",
            "step : 9.57 % , loss : 7.080883502960205\n",
            "step : 9.75 % , loss : 7.311388969421387\n",
            "step : 9.93 % , loss : 7.5983076095581055\n",
            "step : 10.11 % , loss : 7.756889820098877\n",
            "step : 10.28 % , loss : 7.084550857543945\n",
            "step : 10.46 % , loss : 7.5841779708862305\n",
            "step : 10.64 % , loss : 7.27783203125\n",
            "step : 10.82 % , loss : 7.344511032104492\n",
            "step : 10.99 % , loss : 7.123561382293701\n",
            "step : 11.17 % , loss : 7.092635154724121\n",
            "step : 11.35 % , loss : 7.700305938720703\n",
            "step : 11.52 % , loss : 7.505281448364258\n",
            "step : 11.7 % , loss : 7.842780590057373\n",
            "step : 11.88 % , loss : 7.157374858856201\n",
            "step : 12.06 % , loss : 7.195016384124756\n",
            "step : 12.23 % , loss : 7.612512111663818\n",
            "step : 12.41 % , loss : 7.160022258758545\n",
            "step : 12.59 % , loss : 7.268252372741699\n",
            "step : 12.77 % , loss : 7.42763090133667\n",
            "step : 12.94 % , loss : 7.672333717346191\n",
            "step : 13.12 % , loss : 7.161808967590332\n",
            "step : 13.3 % , loss : 7.069126129150391\n",
            "step : 13.48 % , loss : 7.245738506317139\n",
            "step : 13.65 % , loss : 7.162627220153809\n",
            "step : 13.83 % , loss : 7.948543071746826\n",
            "step : 14.01 % , loss : 7.798501968383789\n",
            "step : 14.18 % , loss : 7.884477615356445\n",
            "step : 14.36 % , loss : 7.319398880004883\n",
            "step : 14.54 % , loss : 7.550549030303955\n",
            "step : 14.72 % , loss : 7.1831955909729\n",
            "step : 14.89 % , loss : 7.456923961639404\n",
            "step : 15.07 % , loss : 7.392428874969482\n",
            "step : 15.25 % , loss : 7.323531627655029\n",
            "step : 15.43 % , loss : 7.060490608215332\n",
            "step : 15.6 % , loss : 7.410553455352783\n",
            "step : 15.78 % , loss : 7.16462516784668\n",
            "step : 15.96 % , loss : 7.451274394989014\n",
            "step : 16.13 % , loss : 7.124870777130127\n",
            "step : 16.31 % , loss : 7.005568981170654\n",
            "step : 16.49 % , loss : 7.880735874176025\n",
            "step : 16.67 % , loss : 7.419640064239502\n",
            "step : 16.84 % , loss : 7.064216613769531\n",
            "step : 17.02 % , loss : 7.079064846038818\n",
            "step : 17.2 % , loss : 7.2260847091674805\n",
            "step : 17.38 % , loss : 7.029605388641357\n",
            "step : 17.55 % , loss : 7.099065780639648\n",
            "step : 17.73 % , loss : 7.023701190948486\n",
            "step : 17.91 % , loss : 7.127459526062012\n",
            "step : 18.09 % , loss : 7.50955057144165\n",
            "step : 18.26 % , loss : 7.100240707397461\n",
            "step : 18.44 % , loss : 7.590734004974365\n",
            "step : 18.62 % , loss : 7.232006072998047\n",
            "step : 18.79 % , loss : 7.499954700469971\n",
            "step : 18.97 % , loss : 7.380967617034912\n",
            "step : 19.15 % , loss : 7.021481037139893\n",
            "step : 19.33 % , loss : 7.193517208099365\n",
            "step : 19.5 % , loss : 7.243746280670166\n",
            "step : 19.68 % , loss : 7.186305522918701\n",
            "step : 19.86 % , loss : 7.119297981262207\n",
            "step : 20.04 % , loss : 7.580126762390137\n",
            "step : 20.21 % , loss : 7.22765588760376\n",
            "step : 20.39 % , loss : 7.458267688751221\n",
            "step : 20.57 % , loss : 7.489769458770752\n",
            "step : 20.74 % , loss : 6.803735256195068\n",
            "step : 20.92 % , loss : 7.37177848815918\n",
            "step : 21.1 % , loss : 7.435410022735596\n",
            "step : 21.28 % , loss : 7.250539302825928\n",
            "step : 21.45 % , loss : 7.4350457191467285\n",
            "step : 21.63 % , loss : 7.435503005981445\n",
            "step : 21.81 % , loss : 7.11830472946167\n",
            "step : 21.99 % , loss : 7.279407501220703\n",
            "step : 22.16 % , loss : 7.463723182678223\n",
            "step : 22.34 % , loss : 7.175593376159668\n",
            "step : 22.52 % , loss : 7.059537887573242\n",
            "step : 22.7 % , loss : 7.07546854019165\n",
            "step : 22.87 % , loss : 7.398952484130859\n",
            "step : 23.05 % , loss : 7.117707252502441\n",
            "step : 23.23 % , loss : 7.733310222625732\n",
            "step : 23.4 % , loss : 7.220380783081055\n",
            "step : 23.58 % , loss : 7.281096935272217\n",
            "step : 23.76 % , loss : 7.575868606567383\n",
            "step : 23.94 % , loss : 7.433021068572998\n",
            "step : 24.11 % , loss : 7.122013092041016\n",
            "step : 24.29 % , loss : 7.303362846374512\n",
            "step : 24.47 % , loss : 6.898382663726807\n",
            "step : 24.65 % , loss : 7.239404678344727\n",
            "step : 24.82 % , loss : 7.292825698852539\n",
            "step : 25.0 % , loss : 7.615612030029297\n",
            "step : 25.18 % , loss : 7.226528167724609\n",
            "step : 25.35 % , loss : 7.000980854034424\n",
            "step : 25.53 % , loss : 7.444635391235352\n",
            "step : 25.71 % , loss : 7.1718316078186035\n",
            "step : 25.89 % , loss : 7.476614475250244\n",
            "step : 26.06 % , loss : 7.248017311096191\n",
            "step : 26.24 % , loss : 7.413302421569824\n",
            "step : 26.42 % , loss : 7.148523330688477\n",
            "step : 26.6 % , loss : 7.362189292907715\n",
            "step : 26.77 % , loss : 7.196767330169678\n",
            "step : 26.95 % , loss : 6.929361820220947\n",
            "step : 27.13 % , loss : 7.47215461730957\n",
            "step : 27.3 % , loss : 7.658239364624023\n",
            "step : 27.48 % , loss : 7.3958001136779785\n",
            "step : 27.66 % , loss : 7.5858330726623535\n",
            "step : 27.84 % , loss : 7.062979698181152\n",
            "step : 28.01 % , loss : 7.162467002868652\n",
            "step : 28.19 % , loss : 7.423899173736572\n",
            "step : 28.37 % , loss : 6.986009120941162\n",
            "step : 28.55 % , loss : 6.9150776863098145\n",
            "step : 28.72 % , loss : 7.211660861968994\n",
            "step : 28.9 % , loss : 7.466178894042969\n",
            "step : 29.08 % , loss : 7.407073974609375\n",
            "step : 29.26 % , loss : 8.091813087463379\n",
            "step : 29.43 % , loss : 7.338682651519775\n",
            "step : 29.61 % , loss : 7.467037677764893\n",
            "step : 29.79 % , loss : 7.158818244934082\n",
            "step : 29.96 % , loss : 7.494953632354736\n",
            "step : 30.14 % , loss : 7.3111162185668945\n",
            "step : 30.32 % , loss : 7.17155122756958\n",
            "step : 30.5 % , loss : 6.898562431335449\n",
            "step : 30.67 % , loss : 7.161205291748047\n",
            "step : 30.85 % , loss : 7.160280704498291\n",
            "step : 31.03 % , loss : 7.111191272735596\n",
            "step : 31.21 % , loss : 7.186491012573242\n",
            "step : 31.38 % , loss : 7.349201202392578\n",
            "step : 31.56 % , loss : 7.343357563018799\n",
            "step : 31.74 % , loss : 7.1508259773254395\n",
            "step : 31.91 % , loss : 6.834181785583496\n",
            "step : 32.09 % , loss : 7.310534954071045\n",
            "step : 32.27 % , loss : 7.118531703948975\n",
            "step : 32.45 % , loss : 6.99076509475708\n",
            "step : 32.62 % , loss : 6.8925323486328125\n",
            "step : 32.8 % , loss : 7.215869903564453\n",
            "step : 32.98 % , loss : 7.218602180480957\n",
            "step : 33.16 % , loss : 7.056504249572754\n",
            "step : 33.33 % , loss : 7.215916633605957\n",
            "step : 33.51 % , loss : 7.32820463180542\n",
            "step : 33.69 % , loss : 7.300130367279053\n",
            "step : 33.87 % , loss : 7.54746675491333\n",
            "step : 34.04 % , loss : 7.035177707672119\n",
            "step : 34.22 % , loss : 7.221248149871826\n",
            "step : 34.4 % , loss : 6.719122886657715\n",
            "step : 34.57 % , loss : 7.260497093200684\n",
            "step : 34.75 % , loss : 7.701030731201172\n",
            "step : 34.93 % , loss : 7.661518573760986\n",
            "step : 35.11 % , loss : 6.767899990081787\n",
            "step : 35.28 % , loss : 7.008182048797607\n",
            "step : 35.46 % , loss : 7.773752212524414\n",
            "step : 35.64 % , loss : 7.070556640625\n",
            "step : 35.82 % , loss : 6.838054656982422\n",
            "step : 35.99 % , loss : 7.338010787963867\n",
            "step : 36.17 % , loss : 7.345578670501709\n",
            "step : 36.35 % , loss : 6.525992393493652\n",
            "step : 36.52 % , loss : 7.354710102081299\n",
            "step : 36.7 % , loss : 7.119999408721924\n",
            "step : 36.88 % , loss : 7.420113563537598\n",
            "step : 37.06 % , loss : 7.185394287109375\n",
            "step : 37.23 % , loss : 7.348362922668457\n",
            "step : 37.41 % , loss : 7.256707668304443\n",
            "step : 37.59 % , loss : 7.043233871459961\n",
            "step : 37.77 % , loss : 7.3477959632873535\n",
            "step : 37.94 % , loss : 7.544389724731445\n",
            "step : 38.12 % , loss : 7.5319342613220215\n",
            "step : 38.3 % , loss : 7.247898578643799\n",
            "step : 38.48 % , loss : 7.508667469024658\n",
            "step : 38.65 % , loss : 7.697351932525635\n",
            "step : 38.83 % , loss : 6.952611923217773\n",
            "step : 39.01 % , loss : 7.4711432456970215\n",
            "step : 39.18 % , loss : 7.07645320892334\n",
            "step : 39.36 % , loss : 7.365903854370117\n",
            "step : 39.54 % , loss : 7.032872200012207\n",
            "step : 39.72 % , loss : 7.276050567626953\n",
            "step : 39.89 % , loss : 6.737419605255127\n",
            "step : 40.07 % , loss : 7.64896297454834\n",
            "step : 40.25 % , loss : 7.2277374267578125\n",
            "step : 40.43 % , loss : 7.241456985473633\n",
            "step : 40.6 % , loss : 7.270462989807129\n",
            "step : 40.78 % , loss : 7.108209133148193\n",
            "step : 40.96 % , loss : 7.019740104675293\n",
            "step : 41.13 % , loss : 6.744571685791016\n",
            "step : 41.31 % , loss : 7.5160040855407715\n",
            "step : 41.49 % , loss : 7.221678733825684\n",
            "step : 41.67 % , loss : 7.4804768562316895\n",
            "step : 41.84 % , loss : 7.343857288360596\n",
            "step : 42.02 % , loss : 6.957218170166016\n",
            "step : 42.2 % , loss : 7.174549102783203\n",
            "step : 42.38 % , loss : 7.257152557373047\n",
            "step : 42.55 % , loss : 7.279446601867676\n",
            "step : 42.73 % , loss : 7.23940896987915\n",
            "step : 42.91 % , loss : 7.130733489990234\n",
            "step : 43.09 % , loss : 7.1442670822143555\n",
            "step : 43.26 % , loss : 6.808741569519043\n",
            "step : 43.44 % , loss : 7.095617294311523\n",
            "step : 43.62 % , loss : 6.851503372192383\n",
            "step : 43.79 % , loss : 6.983608722686768\n",
            "step : 43.97 % , loss : 7.22291374206543\n",
            "step : 44.15 % , loss : 6.97389554977417\n",
            "step : 44.33 % , loss : 7.187691688537598\n",
            "step : 44.5 % , loss : 7.413923263549805\n",
            "step : 44.68 % , loss : 6.959488391876221\n",
            "step : 44.86 % , loss : 7.156734466552734\n",
            "step : 45.04 % , loss : 7.05469274520874\n",
            "step : 45.21 % , loss : 7.544816970825195\n",
            "step : 45.39 % , loss : 6.928745746612549\n",
            "step : 45.57 % , loss : 7.057857513427734\n",
            "step : 45.74 % , loss : 6.944584846496582\n",
            "step : 45.92 % , loss : 8.105546951293945\n",
            "step : 46.1 % , loss : 6.627138137817383\n",
            "step : 46.28 % , loss : 7.172673225402832\n",
            "step : 46.45 % , loss : 6.868780136108398\n",
            "step : 46.63 % , loss : 7.197685241699219\n",
            "step : 46.81 % , loss : 7.350970268249512\n",
            "step : 46.99 % , loss : 7.174222946166992\n",
            "step : 47.16 % , loss : 6.898514270782471\n",
            "step : 47.34 % , loss : 6.749882221221924\n",
            "step : 47.52 % , loss : 7.007420063018799\n",
            "step : 47.7 % , loss : 6.9576520919799805\n",
            "step : 47.87 % , loss : 7.181089401245117\n",
            "step : 48.05 % , loss : 7.092900276184082\n",
            "step : 48.23 % , loss : 7.1317572593688965\n",
            "step : 48.4 % , loss : 7.156204700469971\n",
            "step : 48.58 % , loss : 7.230748653411865\n",
            "step : 48.76 % , loss : 7.289597511291504\n",
            "step : 48.94 % , loss : 7.414259433746338\n",
            "step : 49.11 % , loss : 7.279849529266357\n",
            "step : 49.29 % , loss : 7.339713096618652\n",
            "step : 49.47 % , loss : 7.33909797668457\n",
            "step : 49.65 % , loss : 7.2302374839782715\n",
            "step : 49.82 % , loss : 7.637618064880371\n",
            "step : 50.0 % , loss : 7.047563076019287\n",
            "step : 50.18 % , loss : 7.44901180267334\n",
            "step : 50.35 % , loss : 6.7023091316223145\n",
            "step : 50.53 % , loss : 7.0462422370910645\n",
            "step : 50.71 % , loss : 7.046214580535889\n",
            "step : 50.89 % , loss : 7.261866569519043\n",
            "step : 51.06 % , loss : 6.855732440948486\n",
            "step : 51.24 % , loss : 7.354490756988525\n",
            "step : 51.42 % , loss : 7.248100280761719\n",
            "step : 51.6 % , loss : 6.985685348510742\n",
            "step : 51.77 % , loss : 7.085925102233887\n",
            "step : 51.95 % , loss : 7.1630988121032715\n",
            "step : 52.13 % , loss : 7.186140060424805\n",
            "step : 52.3 % , loss : 7.021487712860107\n",
            "step : 52.48 % , loss : 7.133090972900391\n",
            "step : 52.66 % , loss : 7.3512091636657715\n",
            "step : 52.84 % , loss : 7.241467475891113\n",
            "step : 53.01 % , loss : 7.317206382751465\n",
            "step : 53.19 % , loss : 6.944369792938232\n",
            "step : 53.37 % , loss : 6.821227550506592\n",
            "step : 53.55 % , loss : 7.480058193206787\n",
            "step : 53.72 % , loss : 7.259024143218994\n",
            "step : 53.9 % , loss : 7.066375255584717\n",
            "step : 54.08 % , loss : 7.073962211608887\n",
            "step : 54.26 % , loss : 7.1023101806640625\n",
            "step : 54.43 % , loss : 6.852705955505371\n",
            "step : 54.61 % , loss : 7.4405837059021\n",
            "step : 54.79 % , loss : 6.984504222869873\n",
            "step : 54.96 % , loss : 7.224890232086182\n",
            "step : 55.14 % , loss : 7.0605268478393555\n",
            "step : 55.32 % , loss : 7.12336540222168\n",
            "step : 55.5 % , loss : 7.277738094329834\n",
            "step : 55.67 % , loss : 6.719074249267578\n",
            "step : 55.85 % , loss : 7.326614856719971\n",
            "step : 56.03 % , loss : 6.976349353790283\n",
            "step : 56.21 % , loss : 7.0391716957092285\n",
            "step : 56.38 % , loss : 6.5940423011779785\n",
            "step : 56.56 % , loss : 7.070564270019531\n",
            "step : 56.74 % , loss : 7.048939228057861\n",
            "step : 56.91 % , loss : 6.8909196853637695\n",
            "step : 57.09 % , loss : 7.126675128936768\n",
            "step : 57.27 % , loss : 7.135197162628174\n",
            "step : 57.45 % , loss : 7.189371585845947\n",
            "step : 57.62 % , loss : 7.061707019805908\n",
            "step : 57.8 % , loss : 6.986933708190918\n",
            "step : 57.98 % , loss : 6.8265485763549805\n",
            "step : 58.16 % , loss : 7.327909469604492\n",
            "step : 58.33 % , loss : 6.85783576965332\n",
            "step : 58.51 % , loss : 7.087570667266846\n",
            "step : 58.69 % , loss : 6.7339558601379395\n",
            "step : 58.87 % , loss : 7.059910774230957\n",
            "step : 59.04 % , loss : 7.01574182510376\n",
            "step : 59.22 % , loss : 7.111072540283203\n",
            "step : 59.4 % , loss : 7.222994327545166\n",
            "step : 59.57 % , loss : 7.241844177246094\n",
            "step : 59.75 % , loss : 6.871618270874023\n",
            "step : 59.93 % , loss : 7.266909122467041\n",
            "step : 60.11 % , loss : 7.190158843994141\n",
            "step : 60.28 % , loss : 6.9295806884765625\n",
            "step : 60.46 % , loss : 6.837858200073242\n",
            "step : 60.64 % , loss : 7.326770782470703\n",
            "step : 60.82 % , loss : 6.9174580574035645\n",
            "step : 60.99 % , loss : 7.311131000518799\n",
            "step : 61.17 % , loss : 6.600882053375244\n",
            "step : 61.35 % , loss : 7.226217746734619\n",
            "step : 61.52 % , loss : 6.80879020690918\n",
            "step : 61.7 % , loss : 7.65314245223999\n",
            "step : 61.88 % , loss : 7.338829517364502\n",
            "step : 62.06 % , loss : 6.902656078338623\n",
            "step : 62.23 % , loss : 7.044754505157471\n",
            "step : 62.41 % , loss : 6.6908488273620605\n",
            "step : 62.59 % , loss : 6.94059944152832\n",
            "step : 62.77 % , loss : 7.0369462966918945\n",
            "step : 62.94 % , loss : 7.323458671569824\n",
            "step : 63.12 % , loss : 6.890364646911621\n",
            "step : 63.3 % , loss : 6.87393045425415\n",
            "step : 63.48 % , loss : 7.032588481903076\n",
            "step : 63.65 % , loss : 7.015478610992432\n",
            "step : 63.83 % , loss : 7.033775806427002\n",
            "step : 64.01 % , loss : 6.863005638122559\n",
            "step : 64.18 % , loss : 7.271067142486572\n",
            "step : 64.36 % , loss : 7.1259379386901855\n",
            "step : 64.54 % , loss : 7.386413097381592\n",
            "step : 64.72 % , loss : 7.027515411376953\n",
            "step : 64.89 % , loss : 7.0920729637146\n",
            "step : 65.07 % , loss : 7.327347278594971\n",
            "step : 65.25 % , loss : 7.3966145515441895\n",
            "step : 65.43 % , loss : 7.372309684753418\n",
            "step : 65.6 % , loss : 7.397464275360107\n",
            "step : 65.78 % , loss : 7.439931392669678\n",
            "step : 65.96 % , loss : 7.0424418449401855\n",
            "step : 66.13 % , loss : 6.831007957458496\n",
            "step : 66.31 % , loss : 6.8826003074646\n",
            "step : 66.49 % , loss : 7.048586368560791\n",
            "step : 66.67 % , loss : 7.119619846343994\n",
            "step : 66.84 % , loss : 6.6803975105285645\n",
            "step : 67.02 % , loss : 6.771115303039551\n",
            "step : 67.2 % , loss : 6.5283002853393555\n",
            "step : 67.38 % , loss : 7.079407215118408\n",
            "step : 67.55 % , loss : 7.296633720397949\n",
            "step : 67.73 % , loss : 7.0519118309021\n",
            "step : 67.91 % , loss : 6.7892231941223145\n",
            "step : 68.09 % , loss : 7.24259614944458\n",
            "step : 68.26 % , loss : 7.227112770080566\n",
            "step : 68.44 % , loss : 7.130794048309326\n",
            "step : 68.62 % , loss : 7.252872943878174\n",
            "step : 68.79 % , loss : 7.119587421417236\n",
            "step : 68.97 % , loss : 7.110682487487793\n",
            "step : 69.15 % , loss : 6.758749008178711\n",
            "step : 69.33 % , loss : 6.731210708618164\n",
            "step : 69.5 % , loss : 7.265607833862305\n",
            "step : 69.68 % , loss : 7.6129679679870605\n",
            "step : 69.86 % , loss : 7.208591938018799\n",
            "step : 70.04 % , loss : 7.253202438354492\n",
            "step : 70.21 % , loss : 7.043205738067627\n",
            "step : 70.39 % , loss : 7.034746170043945\n",
            "step : 70.57 % , loss : 7.382707595825195\n",
            "step : 70.74 % , loss : 6.947057247161865\n",
            "step : 70.92 % , loss : 7.575881481170654\n",
            "step : 71.1 % , loss : 6.905633926391602\n",
            "step : 71.28 % , loss : 7.052735805511475\n",
            "step : 71.45 % , loss : 6.801549434661865\n",
            "step : 71.63 % , loss : 6.596111297607422\n",
            "step : 71.81 % , loss : 6.692963600158691\n",
            "step : 71.99 % , loss : 6.9730916023254395\n",
            "step : 72.16 % , loss : 6.437860012054443\n",
            "step : 72.34 % , loss : 6.570723056793213\n",
            "step : 72.52 % , loss : 6.993800640106201\n",
            "step : 72.7 % , loss : 7.061821460723877\n",
            "step : 72.87 % , loss : 6.852644443511963\n",
            "step : 73.05 % , loss : 7.0836334228515625\n",
            "step : 73.23 % , loss : 7.206841945648193\n",
            "step : 73.4 % , loss : 7.010899543762207\n",
            "step : 73.58 % , loss : 7.368071556091309\n",
            "step : 73.76 % , loss : 6.84447717666626\n",
            "step : 73.94 % , loss : 6.983665466308594\n",
            "step : 74.11 % , loss : 7.311729431152344\n",
            "step : 74.29 % , loss : 6.988461017608643\n",
            "step : 74.47 % , loss : 7.134057521820068\n",
            "step : 74.65 % , loss : 6.842666149139404\n",
            "step : 74.82 % , loss : 6.833227634429932\n",
            "step : 75.0 % , loss : 6.742537498474121\n",
            "step : 75.18 % , loss : 6.986871719360352\n",
            "step : 75.35 % , loss : 7.2717204093933105\n",
            "step : 75.53 % , loss : 7.161684036254883\n",
            "step : 75.71 % , loss : 6.794528007507324\n",
            "step : 75.89 % , loss : 6.761518478393555\n",
            "step : 76.06 % , loss : 6.495874881744385\n",
            "step : 76.24 % , loss : 6.940088748931885\n",
            "step : 76.42 % , loss : 6.907987117767334\n",
            "step : 76.6 % , loss : 6.274054527282715\n",
            "step : 76.77 % , loss : 7.243100166320801\n",
            "step : 76.95 % , loss : 6.994857311248779\n",
            "step : 77.13 % , loss : 6.724869251251221\n",
            "step : 77.3 % , loss : 7.0360894203186035\n",
            "step : 77.48 % , loss : 7.158857822418213\n",
            "step : 77.66 % , loss : 7.541668891906738\n",
            "step : 77.84 % , loss : 7.270077705383301\n",
            "step : 78.01 % , loss : 6.729861736297607\n",
            "step : 78.19 % , loss : 6.631220817565918\n",
            "step : 78.37 % , loss : 6.691479682922363\n",
            "step : 78.55 % , loss : 6.779673099517822\n",
            "step : 78.72 % , loss : 6.8084259033203125\n",
            "step : 78.9 % , loss : 6.55089807510376\n",
            "step : 79.08 % , loss : 7.150365829467773\n",
            "step : 79.26 % , loss : 7.114917278289795\n",
            "step : 79.43 % , loss : 6.861240863800049\n",
            "step : 79.61 % , loss : 6.8443450927734375\n",
            "step : 79.79 % , loss : 7.009589672088623\n",
            "step : 79.96 % , loss : 7.097308158874512\n",
            "step : 80.14 % , loss : 6.960256576538086\n",
            "step : 80.32 % , loss : 7.152899265289307\n",
            "step : 80.5 % , loss : 7.243154525756836\n",
            "step : 80.67 % , loss : 7.07222318649292\n",
            "step : 80.85 % , loss : 6.646076202392578\n",
            "step : 81.03 % , loss : 6.750292778015137\n",
            "step : 81.21 % , loss : 7.535491466522217\n",
            "step : 81.38 % , loss : 6.921586036682129\n",
            "step : 81.56 % , loss : 6.430154800415039\n",
            "step : 81.74 % , loss : 7.105843544006348\n",
            "step : 81.91 % , loss : 7.088014125823975\n",
            "step : 82.09 % , loss : 6.979808330535889\n",
            "step : 82.27 % , loss : 7.0050787925720215\n",
            "step : 82.45 % , loss : 6.956579208374023\n",
            "step : 82.62 % , loss : 6.879288196563721\n",
            "step : 82.8 % , loss : 7.42449426651001\n",
            "step : 82.98 % , loss : 7.055569648742676\n",
            "step : 83.16 % , loss : 6.681766986846924\n",
            "step : 83.33 % , loss : 6.815301895141602\n",
            "step : 83.51 % , loss : 7.127220630645752\n",
            "step : 83.69 % , loss : 6.54233455657959\n",
            "step : 83.87 % , loss : 7.283901214599609\n",
            "step : 84.04 % , loss : 6.484432697296143\n",
            "step : 84.22 % , loss : 6.978450298309326\n",
            "step : 84.4 % , loss : 7.241876125335693\n",
            "step : 84.57 % , loss : 6.841500282287598\n",
            "step : 84.75 % , loss : 7.0073933601379395\n",
            "step : 84.93 % , loss : 6.810388565063477\n",
            "step : 85.11 % , loss : 6.805723667144775\n",
            "step : 85.28 % , loss : 6.670963764190674\n",
            "step : 85.46 % , loss : 6.773401260375977\n",
            "step : 85.64 % , loss : 7.1852874755859375\n",
            "step : 85.82 % , loss : 7.334250450134277\n",
            "step : 85.99 % , loss : 7.1527018547058105\n",
            "step : 86.17 % , loss : 7.214950084686279\n",
            "step : 86.35 % , loss : 7.527762413024902\n",
            "step : 86.52 % , loss : 6.600890636444092\n",
            "step : 86.7 % , loss : 6.906649112701416\n",
            "step : 86.88 % , loss : 6.836556434631348\n",
            "step : 87.06 % , loss : 7.337697505950928\n",
            "step : 87.23 % , loss : 6.673461437225342\n",
            "step : 87.41 % , loss : 7.150127410888672\n",
            "step : 87.59 % , loss : 6.753635406494141\n",
            "step : 87.77 % , loss : 6.949394226074219\n",
            "step : 87.94 % , loss : 6.7422332763671875\n",
            "step : 88.12 % , loss : 6.623739719390869\n",
            "step : 88.3 % , loss : 7.053817272186279\n",
            "step : 88.48 % , loss : 6.878052711486816\n",
            "step : 88.65 % , loss : 6.65212869644165\n",
            "step : 88.83 % , loss : 6.670964241027832\n",
            "step : 89.01 % , loss : 7.422104358673096\n",
            "step : 89.18 % , loss : 6.516120433807373\n",
            "step : 89.36 % , loss : 7.12632942199707\n",
            "step : 89.54 % , loss : 6.813677787780762\n",
            "step : 89.72 % , loss : 7.1189961433410645\n",
            "step : 89.89 % , loss : 6.763681888580322\n",
            "step : 90.07 % , loss : 6.977221965789795\n",
            "step : 90.25 % , loss : 6.655534744262695\n",
            "step : 90.43 % , loss : 6.565735816955566\n",
            "step : 90.6 % , loss : 6.859385967254639\n",
            "step : 90.78 % , loss : 7.011800765991211\n",
            "step : 90.96 % , loss : 6.415360927581787\n",
            "step : 91.13 % , loss : 6.737299919128418\n",
            "step : 91.31 % , loss : 6.890731334686279\n",
            "step : 91.49 % , loss : 6.640321731567383\n",
            "step : 91.67 % , loss : 7.126380920410156\n",
            "step : 91.84 % , loss : 6.765755653381348\n",
            "step : 92.02 % , loss : 7.2032599449157715\n",
            "step : 92.2 % , loss : 6.695662021636963\n",
            "step : 92.38 % , loss : 6.9478373527526855\n",
            "step : 92.55 % , loss : 6.8263702392578125\n",
            "step : 92.73 % , loss : 6.913242340087891\n",
            "step : 92.91 % , loss : 6.407461166381836\n",
            "step : 93.09 % , loss : 7.362959384918213\n",
            "step : 93.26 % , loss : 6.799386501312256\n",
            "step : 93.44 % , loss : 6.951222896575928\n",
            "step : 93.62 % , loss : 6.734583377838135\n",
            "step : 93.79 % , loss : 6.624989986419678\n",
            "step : 93.97 % , loss : 7.232966423034668\n",
            "step : 94.15 % , loss : 6.643329620361328\n",
            "step : 94.33 % , loss : 6.2437238693237305\n",
            "step : 94.5 % , loss : 6.87455940246582\n",
            "step : 94.68 % , loss : 7.1256632804870605\n",
            "step : 94.86 % , loss : 6.992516994476318\n",
            "step : 95.04 % , loss : 6.744666576385498\n",
            "step : 95.21 % , loss : 6.848685264587402\n",
            "step : 95.39 % , loss : 7.0530829429626465\n",
            "step : 95.57 % , loss : 6.7924580574035645\n",
            "step : 95.74 % , loss : 6.346188545227051\n",
            "step : 95.92 % , loss : 6.991541385650635\n",
            "step : 96.1 % , loss : 6.795109272003174\n",
            "step : 96.28 % , loss : 7.294076919555664\n",
            "step : 96.45 % , loss : 6.8260955810546875\n",
            "step : 96.63 % , loss : 7.014869213104248\n",
            "step : 96.81 % , loss : 6.528767108917236\n",
            "step : 96.99 % , loss : 7.047102451324463\n",
            "step : 97.16 % , loss : 6.836759567260742\n",
            "step : 97.34 % , loss : 6.49676513671875\n",
            "step : 97.52 % , loss : 6.672007083892822\n",
            "step : 97.7 % , loss : 6.906615734100342\n",
            "step : 97.87 % , loss : 6.809905529022217\n",
            "step : 98.05 % , loss : 6.934469223022461\n",
            "step : 98.23 % , loss : 6.851615905761719\n",
            "step : 98.4 % , loss : 6.740196228027344\n",
            "step : 98.58 % , loss : 6.953901767730713\n",
            "step : 98.76 % , loss : 6.681678771972656\n",
            "step : 98.94 % , loss : 7.187110900878906\n",
            "step : 99.11 % , loss : 6.774622440338135\n",
            "step : 99.29 % , loss : 6.642478942871094\n",
            "step : 99.47 % , loss : 6.388001441955566\n",
            "step : 99.65 % , loss : 6.876759052276611\n",
            "step : 99.82 % , loss : 6.267347812652588\n",
            "Epoch: 2 | Time: 5m 37s\n",
            "\tTrain Loss: 7.138 | Train PPL: 1258.426\n",
            "\tVal Loss: 6.849 |  Val PPL: 942.804\n",
            "step : 0.0 % , loss : 6.761870384216309\n",
            "step : 0.18 % , loss : 7.14414119720459\n",
            "step : 0.35 % , loss : 7.285595893859863\n",
            "step : 0.53 % , loss : 6.674086570739746\n",
            "step : 0.71 % , loss : 6.885572910308838\n",
            "step : 0.89 % , loss : 7.221559047698975\n",
            "step : 1.06 % , loss : 6.783976078033447\n",
            "step : 1.24 % , loss : 7.07407808303833\n",
            "step : 1.42 % , loss : 6.71821403503418\n",
            "step : 1.6 % , loss : 6.7015156745910645\n",
            "step : 1.77 % , loss : 6.402191638946533\n",
            "step : 1.95 % , loss : 7.105425834655762\n",
            "step : 2.13 % , loss : 6.6177496910095215\n",
            "step : 2.3 % , loss : 6.653317451477051\n",
            "step : 2.48 % , loss : 6.857664585113525\n",
            "step : 2.66 % , loss : 6.361969470977783\n",
            "step : 2.84 % , loss : 6.779381275177002\n",
            "step : 3.01 % , loss : 6.883866310119629\n",
            "step : 3.19 % , loss : 6.261562347412109\n",
            "step : 3.37 % , loss : 6.516826152801514\n",
            "step : 3.55 % , loss : 6.76613712310791\n",
            "step : 3.72 % , loss : 6.5304179191589355\n",
            "step : 3.9 % , loss : 6.881198406219482\n",
            "step : 4.08 % , loss : 6.311003684997559\n",
            "step : 4.26 % , loss : 6.909337043762207\n",
            "step : 4.43 % , loss : 6.349660396575928\n",
            "step : 4.61 % , loss : 6.658290386199951\n",
            "step : 4.79 % , loss : 6.213473320007324\n",
            "step : 4.96 % , loss : 6.630579471588135\n",
            "step : 5.14 % , loss : 6.640317440032959\n",
            "step : 5.32 % , loss : 6.718984127044678\n",
            "step : 5.5 % , loss : 6.678822994232178\n",
            "step : 5.67 % , loss : 6.468978404998779\n",
            "step : 5.85 % , loss : 6.766412734985352\n",
            "step : 6.03 % , loss : 6.542450904846191\n",
            "step : 6.21 % , loss : 6.820170879364014\n",
            "step : 6.38 % , loss : 6.577104568481445\n",
            "step : 6.56 % , loss : 6.635105133056641\n",
            "step : 6.74 % , loss : 6.828439712524414\n",
            "step : 6.91 % , loss : 6.711902618408203\n",
            "step : 7.09 % , loss : 6.526295185089111\n",
            "step : 7.27 % , loss : 6.957207202911377\n",
            "step : 7.45 % , loss : 6.854011535644531\n",
            "step : 7.62 % , loss : 6.789431571960449\n",
            "step : 7.8 % , loss : 6.400183200836182\n",
            "step : 7.98 % , loss : 6.701808929443359\n",
            "step : 8.16 % , loss : 6.985845565795898\n",
            "step : 8.33 % , loss : 6.193253993988037\n",
            "step : 8.51 % , loss : 6.3281707763671875\n",
            "step : 8.69 % , loss : 6.716882228851318\n",
            "step : 8.87 % , loss : 6.783146381378174\n",
            "step : 9.04 % , loss : 6.624179840087891\n",
            "step : 9.22 % , loss : 6.3316874504089355\n",
            "step : 9.4 % , loss : 7.305785179138184\n",
            "step : 9.57 % , loss : 6.544325351715088\n",
            "step : 9.75 % , loss : 6.358689785003662\n",
            "step : 9.93 % , loss : 7.109195232391357\n",
            "step : 10.11 % , loss : 6.821934223175049\n",
            "step : 10.28 % , loss : 6.7472310066223145\n",
            "step : 10.46 % , loss : 6.7686920166015625\n",
            "step : 10.64 % , loss : 6.754154205322266\n",
            "step : 10.82 % , loss : 6.619304656982422\n",
            "step : 10.99 % , loss : 7.414525985717773\n",
            "step : 11.17 % , loss : 6.964910507202148\n",
            "step : 11.35 % , loss : 6.820529460906982\n",
            "step : 11.52 % , loss : 6.438955307006836\n",
            "step : 11.7 % , loss : 6.998826026916504\n",
            "step : 11.88 % , loss : 6.4368791580200195\n",
            "step : 12.06 % , loss : 7.173676013946533\n",
            "step : 12.23 % , loss : 6.889966011047363\n",
            "step : 12.41 % , loss : 6.4734110832214355\n",
            "step : 12.59 % , loss : 7.415205001831055\n",
            "step : 12.77 % , loss : 6.504745006561279\n",
            "step : 12.94 % , loss : 6.811684608459473\n",
            "step : 13.12 % , loss : 7.066888809204102\n",
            "step : 13.3 % , loss : 6.751601219177246\n",
            "step : 13.48 % , loss : 6.735896587371826\n",
            "step : 13.65 % , loss : 6.650737762451172\n",
            "step : 13.83 % , loss : 6.629613876342773\n",
            "step : 14.01 % , loss : 6.3251729011535645\n",
            "step : 14.18 % , loss : 6.62285041809082\n",
            "step : 14.36 % , loss : 6.5312604904174805\n",
            "step : 14.54 % , loss : 6.514802932739258\n",
            "step : 14.72 % , loss : 6.743626117706299\n",
            "step : 14.89 % , loss : 6.294134616851807\n",
            "step : 15.07 % , loss : 6.479986190795898\n",
            "step : 15.25 % , loss : 6.521108627319336\n",
            "step : 15.43 % , loss : 6.212893486022949\n",
            "step : 15.6 % , loss : 6.759128570556641\n",
            "step : 15.78 % , loss : 6.483287811279297\n",
            "step : 15.96 % , loss : 7.096155643463135\n",
            "step : 16.13 % , loss : 6.1825270652771\n",
            "step : 16.31 % , loss : 6.563396453857422\n",
            "step : 16.49 % , loss : 6.837111949920654\n",
            "step : 16.67 % , loss : 6.748498916625977\n",
            "step : 16.84 % , loss : 6.585749626159668\n",
            "step : 17.02 % , loss : 7.157736778259277\n",
            "step : 17.2 % , loss : 6.698220729827881\n",
            "step : 17.38 % , loss : 6.659880638122559\n",
            "step : 17.55 % , loss : 6.943679332733154\n",
            "step : 17.73 % , loss : 6.7004594802856445\n",
            "step : 17.91 % , loss : 7.0656538009643555\n",
            "step : 18.09 % , loss : 7.043529987335205\n",
            "step : 18.26 % , loss : 6.845160484313965\n",
            "step : 18.44 % , loss : 6.857029914855957\n",
            "step : 18.62 % , loss : 6.726877212524414\n",
            "step : 18.79 % , loss : 6.5481858253479\n",
            "step : 18.97 % , loss : 6.723198890686035\n",
            "step : 19.15 % , loss : 6.660992622375488\n",
            "step : 19.33 % , loss : 6.779138088226318\n",
            "step : 19.5 % , loss : 6.889589309692383\n",
            "step : 19.68 % , loss : 6.4521894454956055\n",
            "step : 19.86 % , loss : 6.351182460784912\n",
            "step : 20.04 % , loss : 7.406991004943848\n",
            "step : 20.21 % , loss : 6.96542501449585\n",
            "step : 20.39 % , loss : 6.802306175231934\n",
            "step : 20.57 % , loss : 6.668878555297852\n",
            "step : 20.74 % , loss : 6.835559368133545\n",
            "step : 20.92 % , loss : 6.849967002868652\n",
            "step : 21.1 % , loss : 6.737563610076904\n",
            "step : 21.28 % , loss : 6.3598551750183105\n",
            "step : 21.45 % , loss : 6.530508995056152\n",
            "step : 21.63 % , loss : 6.8790483474731445\n",
            "step : 21.81 % , loss : 6.794577598571777\n",
            "step : 21.99 % , loss : 6.922420501708984\n",
            "step : 22.16 % , loss : 6.490609169006348\n",
            "step : 22.34 % , loss : 6.820972919464111\n",
            "step : 22.52 % , loss : 6.853348255157471\n",
            "step : 22.7 % , loss : 6.803075790405273\n",
            "step : 22.87 % , loss : 6.65297794342041\n",
            "step : 23.05 % , loss : 6.91160774230957\n",
            "step : 23.23 % , loss : 6.599556922912598\n",
            "step : 23.4 % , loss : 6.535604000091553\n",
            "step : 23.58 % , loss : 6.253283977508545\n",
            "step : 23.76 % , loss : 6.8455915451049805\n",
            "step : 23.94 % , loss : 6.836874485015869\n",
            "step : 24.11 % , loss : 6.686497688293457\n",
            "step : 24.29 % , loss : 6.692853927612305\n",
            "step : 24.47 % , loss : 6.586679458618164\n",
            "step : 24.65 % , loss : 5.901815891265869\n",
            "step : 24.82 % , loss : 6.5344696044921875\n",
            "step : 25.0 % , loss : 7.10330057144165\n",
            "step : 25.18 % , loss : 6.387688636779785\n",
            "step : 25.35 % , loss : 6.475961685180664\n",
            "step : 25.53 % , loss : 6.978878974914551\n",
            "step : 25.71 % , loss : 6.630722522735596\n",
            "step : 25.89 % , loss : 6.669376850128174\n",
            "step : 26.06 % , loss : 6.7143874168396\n",
            "step : 26.24 % , loss : 6.492114543914795\n",
            "step : 26.42 % , loss : 6.586984634399414\n",
            "step : 26.6 % , loss : 6.943443298339844\n",
            "step : 26.77 % , loss : 6.665278434753418\n",
            "step : 26.95 % , loss : 6.707202911376953\n",
            "step : 27.13 % , loss : 7.209958553314209\n",
            "step : 27.3 % , loss : 6.987498760223389\n",
            "step : 27.48 % , loss : 6.64640998840332\n",
            "step : 27.66 % , loss : 6.279626846313477\n",
            "step : 27.84 % , loss : 6.726335525512695\n",
            "step : 28.01 % , loss : 6.83132791519165\n",
            "step : 28.19 % , loss : 6.51746940612793\n",
            "step : 28.37 % , loss : 6.572742462158203\n",
            "step : 28.55 % , loss : 6.576157569885254\n",
            "step : 28.72 % , loss : 6.4996819496154785\n",
            "step : 28.9 % , loss : 6.621462345123291\n",
            "step : 29.08 % , loss : 6.746466159820557\n",
            "step : 29.26 % , loss : 6.308844566345215\n",
            "step : 29.43 % , loss : 6.468405723571777\n",
            "step : 29.61 % , loss : 6.354387283325195\n",
            "step : 29.79 % , loss : 7.081552982330322\n",
            "step : 29.96 % , loss : 6.63502311706543\n",
            "step : 30.14 % , loss : 6.930039405822754\n",
            "step : 30.32 % , loss : 6.872899532318115\n",
            "step : 30.5 % , loss : 6.494847774505615\n",
            "step : 30.67 % , loss : 6.395872116088867\n",
            "step : 30.85 % , loss : 6.354016304016113\n",
            "step : 31.03 % , loss : 6.845648765563965\n",
            "step : 31.21 % , loss : 6.600574016571045\n",
            "step : 31.38 % , loss : 6.688591003417969\n",
            "step : 31.56 % , loss : 7.038941860198975\n",
            "step : 31.74 % , loss : 6.584749698638916\n",
            "step : 31.91 % , loss : 6.469710826873779\n",
            "step : 32.09 % , loss : 6.421157360076904\n",
            "step : 32.27 % , loss : 6.925593376159668\n",
            "step : 32.45 % , loss : 6.613683700561523\n",
            "step : 32.62 % , loss : 6.982395172119141\n",
            "step : 32.8 % , loss : 6.6722731590271\n",
            "step : 32.98 % , loss : 6.689088344573975\n",
            "step : 33.16 % , loss : 6.823808193206787\n",
            "step : 33.33 % , loss : 7.105861186981201\n",
            "step : 33.51 % , loss : 6.806868076324463\n",
            "step : 33.69 % , loss : 6.833529949188232\n",
            "step : 33.87 % , loss : 6.673499584197998\n",
            "step : 34.04 % , loss : 7.186883926391602\n",
            "step : 34.22 % , loss : 6.594564437866211\n",
            "step : 34.4 % , loss : 6.6033616065979\n",
            "step : 34.57 % , loss : 6.4741692543029785\n",
            "step : 34.75 % , loss : 6.804468154907227\n",
            "step : 34.93 % , loss : 6.7093682289123535\n",
            "step : 35.11 % , loss : 6.347592353820801\n",
            "step : 35.28 % , loss : 6.676340579986572\n",
            "step : 35.46 % , loss : 5.953226566314697\n",
            "step : 35.64 % , loss : 6.63731575012207\n",
            "step : 35.82 % , loss : 6.186248779296875\n",
            "step : 35.99 % , loss : 6.43165397644043\n",
            "step : 36.17 % , loss : 6.223357677459717\n",
            "step : 36.35 % , loss : 6.5587477684021\n",
            "step : 36.52 % , loss : 6.850530624389648\n",
            "step : 36.7 % , loss : 6.67096471786499\n",
            "step : 36.88 % , loss : 6.141123294830322\n",
            "step : 37.06 % , loss : 6.957103729248047\n",
            "step : 37.23 % , loss : 6.590251922607422\n",
            "step : 37.41 % , loss : 6.037047863006592\n",
            "step : 37.59 % , loss : 6.9311017990112305\n",
            "step : 37.77 % , loss : 6.629840850830078\n",
            "step : 37.94 % , loss : 6.982419967651367\n",
            "step : 38.12 % , loss : 6.422307014465332\n",
            "step : 38.3 % , loss : 6.2060675621032715\n",
            "step : 38.48 % , loss : 6.780622959136963\n",
            "step : 38.65 % , loss : 6.882266044616699\n",
            "step : 38.83 % , loss : 6.329325199127197\n",
            "step : 39.01 % , loss : 6.658259391784668\n",
            "step : 39.18 % , loss : 6.5968523025512695\n",
            "step : 39.36 % , loss : 6.423051834106445\n",
            "step : 39.54 % , loss : 6.757961750030518\n",
            "step : 39.72 % , loss : 6.431464672088623\n",
            "step : 39.89 % , loss : 6.348412990570068\n",
            "step : 40.07 % , loss : 6.984691619873047\n",
            "step : 40.25 % , loss : 6.803043842315674\n",
            "step : 40.43 % , loss : 6.539299011230469\n",
            "step : 40.6 % , loss : 6.655673980712891\n",
            "step : 40.78 % , loss : 6.167869567871094\n",
            "step : 40.96 % , loss : 6.726994037628174\n",
            "step : 41.13 % , loss : 6.798729419708252\n",
            "step : 41.31 % , loss : 6.826287746429443\n",
            "step : 41.49 % , loss : 6.8064727783203125\n",
            "step : 41.67 % , loss : 6.8056416511535645\n",
            "step : 41.84 % , loss : 6.659116744995117\n",
            "step : 42.02 % , loss : 6.447219371795654\n",
            "step : 42.2 % , loss : 6.893146514892578\n",
            "step : 42.38 % , loss : 6.570801734924316\n",
            "step : 42.55 % , loss : 6.779825687408447\n",
            "step : 42.73 % , loss : 6.3484578132629395\n",
            "step : 42.91 % , loss : 6.663290023803711\n",
            "step : 43.09 % , loss : 6.646100997924805\n",
            "step : 43.26 % , loss : 6.906206130981445\n",
            "step : 43.44 % , loss : 6.691904067993164\n",
            "step : 43.62 % , loss : 6.587534427642822\n",
            "step : 43.79 % , loss : 6.748456954956055\n",
            "step : 43.97 % , loss : 6.359475135803223\n",
            "step : 44.15 % , loss : 6.859929084777832\n",
            "step : 44.33 % , loss : 6.38716983795166\n",
            "step : 44.5 % , loss : 6.748910427093506\n",
            "step : 44.68 % , loss : 7.098327159881592\n",
            "step : 44.86 % , loss : 6.279788017272949\n",
            "step : 45.04 % , loss : 6.409125328063965\n",
            "step : 45.21 % , loss : 6.658908367156982\n",
            "step : 45.39 % , loss : 6.811248779296875\n",
            "step : 45.57 % , loss : 7.231319427490234\n",
            "step : 45.74 % , loss : 6.219366073608398\n",
            "step : 45.92 % , loss : 6.529747009277344\n",
            "step : 46.1 % , loss : 6.52644681930542\n",
            "step : 46.28 % , loss : 6.926258087158203\n",
            "step : 46.45 % , loss : 6.438255786895752\n",
            "step : 46.63 % , loss : 6.555814743041992\n",
            "step : 46.81 % , loss : 6.7721381187438965\n",
            "step : 46.99 % , loss : 6.5365681648254395\n",
            "step : 47.16 % , loss : 7.18269681930542\n",
            "step : 47.34 % , loss : 6.54953145980835\n",
            "step : 47.52 % , loss : 5.843145847320557\n",
            "step : 47.7 % , loss : 6.608435153961182\n",
            "step : 47.87 % , loss : 6.608710289001465\n",
            "step : 48.05 % , loss : 6.698352336883545\n",
            "step : 48.23 % , loss : 6.355957508087158\n",
            "step : 48.4 % , loss : 6.6431169509887695\n",
            "step : 48.58 % , loss : 6.3301520347595215\n",
            "step : 48.76 % , loss : 6.552375793457031\n",
            "step : 48.94 % , loss : 6.850157260894775\n",
            "step : 49.11 % , loss : 6.978138446807861\n",
            "step : 49.29 % , loss : 6.81046724319458\n",
            "step : 49.47 % , loss : 6.7880635261535645\n",
            "step : 49.65 % , loss : 6.635152339935303\n",
            "step : 49.82 % , loss : 6.5794501304626465\n",
            "step : 50.0 % , loss : 6.438138484954834\n",
            "step : 50.18 % , loss : 6.7013092041015625\n",
            "step : 50.35 % , loss : 6.464950084686279\n",
            "step : 50.53 % , loss : 6.429934024810791\n",
            "step : 50.71 % , loss : 6.655716419219971\n",
            "step : 50.89 % , loss : 6.869945049285889\n",
            "step : 51.06 % , loss : 6.235818862915039\n",
            "step : 51.24 % , loss : 6.7547736167907715\n",
            "step : 51.42 % , loss : 6.986722946166992\n",
            "step : 51.6 % , loss : 5.984164714813232\n",
            "step : 51.77 % , loss : 6.778275012969971\n",
            "step : 51.95 % , loss : 6.808714866638184\n",
            "step : 52.13 % , loss : 6.431390762329102\n",
            "step : 52.3 % , loss : 6.4475274085998535\n",
            "step : 52.48 % , loss : 6.145092487335205\n",
            "step : 52.66 % , loss : 6.775323390960693\n",
            "step : 52.84 % , loss : 6.726949214935303\n",
            "step : 53.01 % , loss : 6.27573299407959\n",
            "step : 53.19 % , loss : 6.604889869689941\n",
            "step : 53.37 % , loss : 6.64600944519043\n",
            "step : 53.55 % , loss : 6.20945930480957\n",
            "step : 53.72 % , loss : 6.650466442108154\n",
            "step : 53.9 % , loss : 6.936647891998291\n",
            "step : 54.08 % , loss : 6.074453353881836\n",
            "step : 54.26 % , loss : 6.264620780944824\n",
            "step : 54.43 % , loss : 6.6192240715026855\n",
            "step : 54.61 % , loss : 6.276215553283691\n",
            "step : 54.79 % , loss : 6.287517070770264\n",
            "step : 54.96 % , loss : 6.344074249267578\n",
            "step : 55.14 % , loss : 6.378289699554443\n",
            "step : 55.32 % , loss : 6.429596424102783\n",
            "step : 55.5 % , loss : 6.530156135559082\n",
            "step : 55.67 % , loss : 6.795324802398682\n",
            "step : 55.85 % , loss : 7.038212299346924\n",
            "step : 56.03 % , loss : 6.676661014556885\n",
            "step : 56.21 % , loss : 7.036685466766357\n",
            "step : 56.38 % , loss : 6.196540832519531\n",
            "step : 56.56 % , loss : 6.428791522979736\n",
            "step : 56.74 % , loss : 6.2591986656188965\n",
            "step : 56.91 % , loss : 6.575492858886719\n",
            "step : 57.09 % , loss : 6.542935848236084\n",
            "step : 57.27 % , loss : 6.853026390075684\n",
            "step : 57.45 % , loss : 6.475775241851807\n",
            "step : 57.62 % , loss : 6.770441055297852\n",
            "step : 57.8 % , loss : 5.914368152618408\n",
            "step : 57.98 % , loss : 6.918416500091553\n",
            "step : 58.16 % , loss : 6.10133695602417\n",
            "step : 58.33 % , loss : 6.350249767303467\n",
            "step : 58.51 % , loss : 6.5550408363342285\n",
            "step : 58.69 % , loss : 6.929859161376953\n",
            "step : 58.87 % , loss : 6.183073997497559\n",
            "step : 59.04 % , loss : 6.376808166503906\n",
            "step : 59.22 % , loss : 6.115750312805176\n",
            "step : 59.4 % , loss : 6.551534175872803\n",
            "step : 59.57 % , loss : 6.216266632080078\n",
            "step : 59.75 % , loss : 6.397310733795166\n",
            "step : 59.93 % , loss : 6.1163859367370605\n",
            "step : 60.11 % , loss : 6.5073933601379395\n",
            "step : 60.28 % , loss : 6.8900065422058105\n",
            "step : 60.46 % , loss : 6.483560562133789\n",
            "step : 60.64 % , loss : 6.512547016143799\n",
            "step : 60.82 % , loss : 6.534833908081055\n",
            "step : 60.99 % , loss : 6.812387466430664\n",
            "step : 61.17 % , loss : 6.760361194610596\n",
            "step : 61.35 % , loss : 6.561005592346191\n",
            "step : 61.52 % , loss : 6.394947528839111\n",
            "step : 61.7 % , loss : 6.679089546203613\n",
            "step : 61.88 % , loss : 6.351004123687744\n",
            "step : 62.06 % , loss : 6.4667649269104\n",
            "step : 62.23 % , loss : 7.04511022567749\n",
            "step : 62.41 % , loss : 6.238832473754883\n",
            "step : 62.59 % , loss : 6.238719463348389\n",
            "step : 62.77 % , loss : 6.657217502593994\n",
            "step : 62.94 % , loss : 6.380980014801025\n",
            "step : 63.12 % , loss : 6.8121337890625\n",
            "step : 63.3 % , loss : 6.60683012008667\n",
            "step : 63.48 % , loss : 6.489284038543701\n",
            "step : 63.65 % , loss : 6.486611366271973\n",
            "step : 63.83 % , loss : 6.697460651397705\n",
            "step : 64.01 % , loss : 6.557875156402588\n",
            "step : 64.18 % , loss : 7.18756103515625\n",
            "step : 64.36 % , loss : 6.553680896759033\n",
            "step : 64.54 % , loss : 6.452056884765625\n",
            "step : 64.72 % , loss : 6.752036094665527\n",
            "step : 64.89 % , loss : 6.376970291137695\n",
            "step : 65.07 % , loss : 6.45980978012085\n",
            "step : 65.25 % , loss : 6.683781623840332\n",
            "step : 65.43 % , loss : 6.3435750007629395\n",
            "step : 65.6 % , loss : 6.670093536376953\n",
            "step : 65.78 % , loss : 6.479720115661621\n",
            "step : 65.96 % , loss : 6.7467780113220215\n",
            "step : 66.13 % , loss : 6.103779315948486\n",
            "step : 66.31 % , loss : 6.400045871734619\n",
            "step : 66.49 % , loss : 6.078679084777832\n",
            "step : 66.67 % , loss : 6.2262372970581055\n",
            "step : 66.84 % , loss : 6.425534248352051\n",
            "step : 67.02 % , loss : 6.425189018249512\n",
            "step : 67.2 % , loss : 6.585221767425537\n",
            "step : 67.38 % , loss : 6.292149066925049\n",
            "step : 67.55 % , loss : 6.481189727783203\n",
            "step : 67.73 % , loss : 6.3569841384887695\n",
            "step : 67.91 % , loss : 6.174301624298096\n",
            "step : 68.09 % , loss : 6.14481258392334\n",
            "step : 68.26 % , loss : 6.44653844833374\n",
            "step : 68.44 % , loss : 6.553896427154541\n",
            "step : 68.62 % , loss : 6.570389270782471\n",
            "step : 68.79 % , loss : 6.480192184448242\n",
            "step : 68.97 % , loss : 6.953555583953857\n",
            "step : 69.15 % , loss : 6.658652305603027\n",
            "step : 69.33 % , loss : 6.720190525054932\n",
            "step : 69.5 % , loss : 6.289482593536377\n",
            "step : 69.68 % , loss : 6.612356662750244\n",
            "step : 69.86 % , loss : 6.483957767486572\n",
            "step : 70.04 % , loss : 6.813156604766846\n",
            "step : 70.21 % , loss : 6.595378398895264\n",
            "step : 70.39 % , loss : 6.731861114501953\n",
            "step : 70.57 % , loss : 6.778782367706299\n",
            "step : 70.74 % , loss : 6.393404483795166\n",
            "step : 70.92 % , loss : 6.711868762969971\n",
            "step : 71.1 % , loss : 6.794590950012207\n",
            "step : 71.28 % , loss : 6.16817045211792\n",
            "step : 71.45 % , loss : 6.666440486907959\n",
            "step : 71.63 % , loss : 6.6225738525390625\n",
            "step : 71.81 % , loss : 6.622382640838623\n",
            "step : 71.99 % , loss : 6.606025218963623\n",
            "step : 72.16 % , loss : 6.731751918792725\n",
            "step : 72.34 % , loss : 6.697695255279541\n",
            "step : 72.52 % , loss : 6.215677261352539\n",
            "step : 72.7 % , loss : 7.295068264007568\n",
            "step : 72.87 % , loss : 6.438118934631348\n",
            "step : 73.05 % , loss : 6.358302116394043\n",
            "step : 73.23 % , loss : 7.328751087188721\n",
            "step : 73.4 % , loss : 6.352539539337158\n",
            "step : 73.58 % , loss : 6.018568992614746\n",
            "step : 73.76 % , loss : 6.218039035797119\n",
            "step : 73.94 % , loss : 6.523725509643555\n",
            "step : 74.11 % , loss : 6.399503707885742\n",
            "step : 74.29 % , loss : 6.53316593170166\n",
            "step : 74.47 % , loss : 6.881117820739746\n",
            "step : 74.65 % , loss : 6.276379108428955\n",
            "step : 74.82 % , loss : 6.586885452270508\n",
            "step : 75.0 % , loss : 6.3598151206970215\n",
            "step : 75.18 % , loss : 6.729469299316406\n",
            "step : 75.35 % , loss : 6.745400905609131\n",
            "step : 75.53 % , loss : 6.45616340637207\n",
            "step : 75.71 % , loss : 6.873724937438965\n",
            "step : 75.89 % , loss : 6.2745680809021\n",
            "step : 76.06 % , loss : 6.474905490875244\n",
            "step : 76.24 % , loss : 6.017543315887451\n",
            "step : 76.42 % , loss : 6.7020649909973145\n",
            "step : 76.6 % , loss : 6.387192726135254\n",
            "step : 76.77 % , loss : 6.510349750518799\n",
            "step : 76.95 % , loss : 6.077914237976074\n",
            "step : 77.13 % , loss : 6.46514368057251\n",
            "step : 77.3 % , loss : 6.220019817352295\n",
            "step : 77.48 % , loss : 6.713968753814697\n",
            "step : 77.66 % , loss : 6.463890075683594\n",
            "step : 77.84 % , loss : 6.587039470672607\n",
            "step : 78.01 % , loss : 6.273665428161621\n",
            "step : 78.19 % , loss : 6.808676719665527\n",
            "step : 78.37 % , loss : 6.372490406036377\n",
            "step : 78.55 % , loss : 6.551849365234375\n",
            "step : 78.72 % , loss : 6.557090759277344\n",
            "step : 78.9 % , loss : 6.302011013031006\n",
            "step : 79.08 % , loss : 6.745619297027588\n",
            "step : 79.26 % , loss : 6.092584133148193\n",
            "step : 79.43 % , loss : 6.7590107917785645\n",
            "step : 79.61 % , loss : 6.400014400482178\n",
            "step : 79.79 % , loss : 6.55560302734375\n",
            "step : 79.96 % , loss : 6.366185665130615\n",
            "step : 80.14 % , loss : 6.256777286529541\n",
            "step : 80.32 % , loss : 6.350732803344727\n",
            "step : 80.5 % , loss : 6.448176383972168\n",
            "step : 80.67 % , loss : 6.660971164703369\n",
            "step : 80.85 % , loss : 6.6565093994140625\n",
            "step : 81.03 % , loss : 6.3403801918029785\n",
            "step : 81.21 % , loss : 6.826412677764893\n",
            "step : 81.38 % , loss : 6.620009422302246\n",
            "step : 81.56 % , loss : 7.200056076049805\n",
            "step : 81.74 % , loss : 7.130270004272461\n",
            "step : 81.91 % , loss : 6.174366474151611\n",
            "step : 82.09 % , loss : 6.960747241973877\n",
            "step : 82.27 % , loss : 6.432734489440918\n",
            "step : 82.45 % , loss : 6.425187110900879\n",
            "step : 82.62 % , loss : 6.828481674194336\n",
            "step : 82.8 % , loss : 6.316197872161865\n",
            "step : 82.98 % , loss : 6.7597737312316895\n",
            "step : 83.16 % , loss : 6.664011001586914\n",
            "step : 83.33 % , loss : 6.266873359680176\n",
            "step : 83.51 % , loss : 6.5758466720581055\n",
            "step : 83.69 % , loss : 5.9430012702941895\n",
            "step : 83.87 % , loss : 6.583210468292236\n",
            "step : 84.04 % , loss : 6.219979763031006\n",
            "step : 84.22 % , loss : 6.309566974639893\n",
            "step : 84.4 % , loss : 6.712621212005615\n",
            "step : 84.57 % , loss : 6.4158220291137695\n",
            "step : 84.75 % , loss : 5.96234130859375\n",
            "step : 84.93 % , loss : 6.241522789001465\n",
            "step : 85.11 % , loss : 7.481328010559082\n",
            "step : 85.28 % , loss : 6.543496131896973\n",
            "step : 85.46 % , loss : 6.368255615234375\n",
            "step : 85.64 % , loss : 6.729621887207031\n",
            "step : 85.82 % , loss : 6.251535415649414\n",
            "step : 85.99 % , loss : 6.404233932495117\n",
            "step : 86.17 % , loss : 7.0159912109375\n",
            "step : 86.35 % , loss : 5.940293788909912\n",
            "step : 86.52 % , loss : 6.651419639587402\n",
            "step : 86.7 % , loss : 6.236982345581055\n",
            "step : 86.88 % , loss : 6.163146495819092\n",
            "step : 87.06 % , loss : 6.8148040771484375\n",
            "step : 87.23 % , loss : 6.081480979919434\n",
            "step : 87.41 % , loss : 6.440886497497559\n",
            "step : 87.59 % , loss : 6.175178050994873\n",
            "step : 87.77 % , loss : 6.3722310066223145\n",
            "step : 87.94 % , loss : 6.357224464416504\n",
            "step : 88.12 % , loss : 6.0317487716674805\n",
            "step : 88.3 % , loss : 6.1736979484558105\n",
            "step : 88.48 % , loss : 6.95599365234375\n",
            "step : 88.65 % , loss : 6.300462245941162\n",
            "step : 88.83 % , loss : 6.031830310821533\n",
            "step : 89.01 % , loss : 6.069554328918457\n",
            "step : 89.18 % , loss : 6.6056227684021\n",
            "step : 89.36 % , loss : 6.352060794830322\n",
            "step : 89.54 % , loss : 6.981522560119629\n",
            "step : 89.72 % , loss : 6.610571384429932\n",
            "step : 89.89 % , loss : 7.045428276062012\n",
            "step : 90.07 % , loss : 6.256656169891357\n",
            "step : 90.25 % , loss : 6.705387592315674\n",
            "step : 90.43 % , loss : 6.13105583190918\n",
            "step : 90.6 % , loss : 6.464195251464844\n",
            "step : 90.78 % , loss : 6.37457275390625\n",
            "step : 90.96 % , loss : 6.693969249725342\n",
            "step : 91.13 % , loss : 6.642518997192383\n",
            "step : 91.31 % , loss : 6.456496715545654\n",
            "step : 91.49 % , loss : 6.081722259521484\n",
            "step : 91.67 % , loss : 6.2636637687683105\n",
            "step : 91.84 % , loss : 6.711924076080322\n",
            "step : 92.02 % , loss : 6.883968353271484\n",
            "step : 92.2 % , loss : 6.895918846130371\n",
            "step : 92.38 % , loss : 6.277090072631836\n",
            "step : 92.55 % , loss : 6.3451924324035645\n",
            "step : 92.73 % , loss : 6.751081943511963\n",
            "step : 92.91 % , loss : 6.418429851531982\n",
            "step : 93.09 % , loss : 6.924344539642334\n",
            "step : 93.26 % , loss : 5.995641708374023\n",
            "step : 93.44 % , loss : 6.463581562042236\n",
            "step : 93.62 % , loss : 6.071603298187256\n",
            "step : 93.79 % , loss : 6.794848442077637\n",
            "step : 93.97 % , loss : 6.36447811126709\n",
            "step : 94.15 % , loss : 6.3574700355529785\n",
            "step : 94.33 % , loss : 6.188828945159912\n",
            "step : 94.5 % , loss : 6.596678733825684\n",
            "step : 94.68 % , loss : 6.28604793548584\n",
            "step : 94.86 % , loss : 6.391113758087158\n",
            "step : 95.04 % , loss : 6.484576225280762\n",
            "step : 95.21 % , loss : 6.378083229064941\n",
            "step : 95.39 % , loss : 6.328183650970459\n",
            "step : 95.57 % , loss : 6.418873310089111\n",
            "step : 95.74 % , loss : 6.3912034034729\n",
            "step : 95.92 % , loss : 6.275735378265381\n",
            "step : 96.1 % , loss : 6.26493501663208\n",
            "step : 96.28 % , loss : 6.83205509185791\n",
            "step : 96.45 % , loss : 6.25663948059082\n",
            "step : 96.63 % , loss : 6.220577716827393\n",
            "step : 96.81 % , loss : 6.194070816040039\n",
            "step : 96.99 % , loss : 6.654824256896973\n",
            "step : 97.16 % , loss : 6.004194259643555\n",
            "step : 97.34 % , loss : 6.067870140075684\n",
            "step : 97.52 % , loss : 5.8489885330200195\n",
            "step : 97.7 % , loss : 6.355464458465576\n",
            "step : 97.87 % , loss : 6.691296577453613\n",
            "step : 98.05 % , loss : 6.689693450927734\n",
            "step : 98.23 % , loss : 6.3087358474731445\n",
            "step : 98.4 % , loss : 6.9806718826293945\n",
            "step : 98.58 % , loss : 6.472037315368652\n",
            "step : 98.76 % , loss : 6.785213947296143\n",
            "step : 98.94 % , loss : 6.424928665161133\n",
            "step : 99.11 % , loss : 6.582732200622559\n",
            "step : 99.29 % , loss : 6.485015392303467\n",
            "step : 99.47 % , loss : 6.666308403015137\n",
            "step : 99.65 % , loss : 6.321848392486572\n",
            "step : 99.82 % , loss : 6.7151641845703125\n",
            "Epoch: 3 | Time: 5m 37s\n",
            "\tTrain Loss: 6.587 | Train PPL: 725.773\n",
            "\tVal Loss: 6.465 |  Val PPL: 642.318\n"
          ]
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_data(train_pth, test_pth, type=\"train\"):\n",
        "  arr_train, arr_test =\"\", \"\"\n",
        "  with open(train_pth, 'r') as f:\n",
        "    arr_train = f.read()\n",
        "  with open(test_pth, 'r') as f:\n",
        "    arr_test = f.read()\n",
        "  arr_train, arr_test = arr_train[1:-1], arr_test[1:-1]\n",
        "  arr_train, arr_test = arr_train.split(\", \"), arr_test.split(\", \")\n",
        "  data_train = [float(x) for x in arr_train]\n",
        "  data_test = [float(x) for x in arr_test]\n",
        "  time = [i for i in range(len(data_train))]\n",
        "  plt.plot(time, data_train, color='b', label='train')\n",
        "  plt.plot(time, data_test, color='r', label='test')\n",
        "  plt.xlabel(\"epoch\")\n",
        "  plt.ylabel(\"loss\")\n",
        "  plt.title(type)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "visualize_data('result/train_loss.txt', 'result/test_loss.txt', 'train')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "O8aNvRS_BIHH",
        "outputId": "c71b7122-9f10-47cd-f1af-6d8b804d74ca"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_data('result/test_loss.txt', 'test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "8DKishrPOVzA",
        "outputId": "af4284b7-5846-402d-f8b5-edf41c90b20f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "P_QiUVcVO2eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KaXeXyIbauPx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}